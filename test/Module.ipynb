{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "import torch\n",
    "from kitti.kitti_dataset import get_dataloader\n",
    "import yaml\n",
    "from easydict import EasyDict\n",
    "from pathlib import Path\n",
    "from basic.utils.vis_utils import VisualWindow\n",
    "# %matplotlib inline\n",
    "torch.cuda.empty_cache()\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# DataLoader"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ph/Desktop/PointCloud/utils_my/kitti/kitti_dataset.py:30: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.\n",
      "  cfg = EasyDict(yaml.load(f))\n"
     ]
    }
   ],
   "source": [
    "cfg_path = Path(\"../kitti/cfg/kitti_dataset.yaml\")\n",
    "batch_size = 4\n",
    "dataloader = get_dataloader(data_cfg_path=cfg_path, class_name_list=['Car'], batch_size=batch_size)  # 'Pedestrian','Cyclist'"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input voxels shape: torch.Size([63662, 5, 4])\n"
     ]
    },
    {
     "data": {
      "text/plain": "{'frame_id': array(['006631', '006627', '006382', '006995'], dtype='<U6'),\n 'gt_boxes': tensor([[[ 2.9326e+01,  8.4339e+00, -7.4018e-01,  3.8006e+00,  1.5304e+00,\n            1.5709e+00, -2.7242e+00,  1.0000e+00],\n          [ 4.9416e+01, -1.9758e+00, -5.5213e-01,  3.9830e+00,  1.6013e+00,\n            1.9459e+00, -2.7342e+00,  1.0000e+00],\n          [ 3.0372e+01,  1.2644e+01, -7.9539e-01,  4.5607e+00,  1.6520e+00,\n            1.6418e+00,  4.1902e-01,  1.0000e+00],\n          [ 4.3164e+01, -3.0087e+00, -6.7769e-01,  4.2161e+00,  1.8344e+00,\n            1.4493e+00, -2.7042e+00,  1.0000e+00],\n          [ 1.2676e+01,  1.5234e+01, -5.4629e-01,  3.3242e+00,  1.6013e+00,\n            1.5405e+00, -1.8442e+00,  1.0000e+00],\n          [ 3.2002e+01,  2.2141e+01, -2.8475e-01,  3.7499e+00,  1.6925e+00,\n            1.7331e+00, -1.1410e+00,  1.0000e+00],\n          [ 1.0148e+01,  8.7813e+00, -7.8756e-01,  3.4762e+00,  1.6925e+00,\n            1.6013e+00,  5.6902e-01,  1.0000e+00],\n          [ 5.4691e+00,  5.6361e+00, -9.3528e-01,  3.5573e+00,  1.5709e+00,\n            1.5608e+00,  4.5902e-01,  1.0000e+00],\n          [ 3.3785e+01, -8.2301e+00, -9.1867e-01,  4.2161e+00,  1.8344e+00,\n            1.4493e+00, -2.7442e+00,  1.0000e+00],\n          [ 1.4621e+01,  9.0229e+00, -7.9341e-01,  2.6857e+00,  1.4087e+00,\n            1.7128e+00,  3.1902e-01,  1.0000e+00],\n          [ 3.5357e+01,  1.2271e+01, -6.8675e-01,  3.6992e+00,  1.6114e+00,\n            1.5810e+00,  4.0902e-01,  1.0000e+00],\n          [ 2.2474e+01,  9.4569e+00, -6.4244e-01,  4.5607e+00,  1.6520e+00,\n            1.6418e+00,  3.8902e-01,  1.0000e+00],\n          [ 2.9311e+01,  1.5011e+01, -9.1464e-01,  4.2161e+00,  1.5506e+00,\n            1.5405e+00,  3.8902e-01,  1.0000e+00],\n          [ 2.1209e+01,  4.6015e+00, -8.6025e-01,  4.0337e+00,  1.5810e+00,\n            1.6722e+00, -2.7242e+00,  1.0000e+00],\n          [ 2.2908e+01,  1.3258e+01, -6.0234e-01,  3.9627e+00,  1.5709e+00,\n            1.4493e+00,  1.1590e+00,  1.0000e+00],\n          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n            0.0000e+00,  0.0000e+00,  0.0000e+00],\n          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n            0.0000e+00,  0.0000e+00,  0.0000e+00]],\n \n         [[ 2.1993e+00, -2.2632e+00, -8.0711e-01,  3.6533e+00,  1.5657e+00,\n            1.5560e+00,  2.2964e-01,  1.0000e+00],\n          [ 2.4561e+01,  1.2254e+01, -6.3928e-01,  3.7016e+00,  1.5174e+00,\n            1.7977e+00, -2.8404e+00,  1.0000e+00],\n          [ 3.6283e+00,  6.2572e+00, -1.0382e+00,  3.5760e+00,  1.4111e+00,\n            1.4497e+00, -2.8404e+00,  1.0000e+00],\n          [ 3.8695e+01,  1.5927e+01, -7.8231e-01,  4.1752e+00,  1.2854e+00,\n            1.3337e+00, -2.8404e+00,  1.0000e+00],\n          [ 1.2767e+01,  7.0323e+00, -9.3032e-01,  3.3537e+00,  1.5077e+00,\n            1.4014e+00, -2.8604e+00,  1.0000e+00],\n          [ 3.2830e+01, -6.7894e+00, -5.8007e-02,  3.7113e+00,  1.5464e+00,\n            1.4304e+00, -1.0804e+00,  1.0000e+00],\n          [ 3.3731e+01,  2.1232e+01, -9.0206e-01,  3.5470e+00,  1.4884e+00,\n            1.3531e+00, -2.9004e+00,  1.0000e+00],\n          [ 2.4139e+01,  1.8869e+01, -9.8075e-01,  3.9336e+00,  1.4884e+00,\n            1.4304e+00, -2.8304e+00,  1.0000e+00],\n          [ 3.5163e+01,  1.2315e+01, -4.7741e-01,  3.4890e+00,  1.6140e+00,\n            1.4691e+00,  2.9964e-01,  1.0000e+00],\n          [ 2.9402e+01,  3.0120e+01, -1.6329e-01,  3.6340e+00,  1.6817e+00,\n            1.6334e+00,  2.8964e-01,  1.0000e+00],\n          [ 1.9474e+01,  2.3785e+00, -8.0918e-01,  3.1217e+00,  1.5174e+00,\n            1.3627e+00,  2.9964e-01,  1.0000e+00],\n          [ 2.3263e+01,  8.0209e+00, -7.4735e-01,  3.3730e+00,  1.4594e+00,\n            1.3241e+00,  4.6964e-01,  1.0000e+00],\n          [ 1.8127e+01,  1.0158e+01, -8.4704e-01,  3.5953e+00,  1.5077e+00,\n            1.4304e+00,  1.0196e+00,  1.0000e+00],\n          [ 9.2475e+00,  2.3371e+00, -8.8600e-01,  3.8563e+00,  1.6817e+00,\n            1.4111e+00,  2.9028e+00,  1.0000e+00],\n          [ 2.9744e+01,  1.2793e+01, -4.8000e-01,  4.3395e+00,  1.6140e+00,\n            1.6044e+00, -2.8404e+00,  1.0000e+00],\n          [ 4.0333e+01,  8.3690e+00, -4.8409e-02,  3.8079e+00,  1.6237e+00,\n            1.5464e+00, -3.0604e+00,  1.0000e+00],\n          [ 4.4771e+01,  1.7155e+01, -1.6799e-01,  4.3782e+00,  1.8073e+00,\n            1.9040e+00, -2.8204e+00,  1.0000e+00]],\n \n         [[ 3.3088e+01, -2.4066e+01, -9.2483e-01,  4.4779e+00,  1.8701e+00,\n            1.5376e+00, -1.0095e+00,  1.0000e+00],\n          [ 4.3557e+01, -2.6334e+01, -1.0018e+00,  4.6753e+00,  1.9532e+00,\n            1.7558e+00,  2.5137e+00,  1.0000e+00],\n          [ 1.6495e+01, -1.8544e+01, -6.1166e-01,  3.4077e+00,  1.6415e+00,\n            1.5792e+00,  1.7837e+00,  1.0000e+00],\n          [ 2.0634e+01, -1.0539e+01, -7.7967e-01,  3.3246e+00,  1.7247e+00,\n            1.6727e+00, -4.8952e-01,  1.0000e+00],\n          [ 2.9417e+01, -2.2137e+00, -9.0084e-01,  3.9896e+00,  1.6415e+00,\n            1.5480e+00,  2.5637e+00,  1.0000e+00],\n          [ 8.8965e+00, -6.7384e+00, -9.2615e-01,  3.7402e+00,  1.6831e+00,\n            1.4649e+00, -1.6395e+00,  1.0000e+00],\n          [ 2.0890e+01, -3.5304e-01, -8.8776e-01,  3.9999e+00,  1.6935e+00,\n            1.5169e+00, -2.0295e+00,  1.0000e+00],\n          [ 1.9606e+01, -6.4744e+00, -8.8351e-01,  4.5610e+00,  1.7454e+00,\n            1.4961e+00,  2.6237e+00,  1.0000e+00],\n          [ 3.5087e+01, -6.5206e-01, -8.3003e-01,  3.3350e+00,  1.5376e+00,\n            1.5273e+00,  2.5437e+00,  1.0000e+00],\n          [ 2.0866e+01, -1.8800e+01, -8.2683e-01,  3.3766e+00,  1.5376e+00,\n            1.4857e+00, -4.1952e-01,  1.0000e+00],\n          [ 4.0590e+01, -1.0934e+01, -8.4931e-01,  4.0519e+00,  1.6623e+00,\n            1.5376e+00,  2.6337e+00,  1.0000e+00],\n          [ 2.6503e+01, -1.2522e+01, -7.4319e-01,  3.8129e+00,  1.6935e+00,\n            1.6000e+00, -4.4952e-01,  1.0000e+00],\n          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n            0.0000e+00,  0.0000e+00,  0.0000e+00],\n          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n            0.0000e+00,  0.0000e+00,  0.0000e+00],\n          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n            0.0000e+00,  0.0000e+00,  0.0000e+00],\n          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n            0.0000e+00,  0.0000e+00,  0.0000e+00],\n          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n            0.0000e+00,  0.0000e+00,  0.0000e+00]],\n \n         [[ 4.0644e+01,  3.6064e+01, -3.7105e-01,  3.7375e+00,  1.5565e+00,\n            1.4412e+00,  6.6052e-01,  1.0000e+00],\n          [ 2.0158e+01,  2.0390e+01, -5.8796e-01,  3.7952e+00,  1.5181e+00,\n            1.6238e+00,  6.5052e-01,  1.0000e+00],\n          [ 1.2745e+01,  1.4763e+01, -8.0442e-01,  3.1034e+00,  1.5085e+00,\n            1.3547e+00,  6.8052e-01,  1.0000e+00],\n          [ 1.0097e+01,  1.7461e+01, -7.9958e-01,  4.0354e+00,  1.5469e+00,\n            1.3932e+00,  6.6052e-01,  1.0000e+00],\n          [ 2.2721e+01,  3.4559e+01, -6.4339e-01,  3.3724e+00,  1.3067e+00,\n            1.4220e+00,  1.0052e-01,  1.0000e+00],\n          [ 8.8970e+00,  2.4572e+01, -3.6676e-01,  3.7279e+00,  1.4989e+00,\n            1.4316e+00,  7.2052e-01,  1.0000e+00],\n          [ 5.4508e+00,  8.3247e+00, -7.9691e-01,  3.1322e+00,  1.4028e+00,\n            1.4700e+00,  6.7052e-01,  1.0000e+00],\n          [ 2.3556e+01,  1.6501e+01, -2.0833e-01,  3.4589e+00,  1.5277e+00,\n            1.4412e+00, -2.5227e+00,  1.0000e+00],\n          [ 1.9627e+01,  8.6203e+00, -6.2139e-01,  3.3436e+00,  1.5085e+00,\n            1.4220e+00,  3.0505e+00,  1.0000e+00],\n          [ 6.5701e+01,  1.8278e+01,  8.5246e-01,  4.5446e+00,  1.7391e+00,\n            2.3828e+00,  7.0052e-01,  1.0000e+00],\n          [ 8.6618e+00,  1.3341e+00, -7.6296e-01,  3.5742e+00,  1.4989e+00,\n            1.4220e+00, -1.2948e-01,  1.0000e+00],\n          [ 4.2212e+00,  1.3862e+01, -8.3780e-01,  4.3909e+00,  1.5565e+00,\n            1.2683e+00,  2.1805e+00,  1.0000e+00],\n          [ 3.5592e+01,  7.5562e+00, -1.0516e+00,  3.4589e+00,  1.4796e+00,\n            1.3547e+00, -1.2427e+00,  1.0000e+00],\n          [ 2.5743e+01,  7.5203e+00, -9.6650e-01,  4.2083e+00,  1.5085e+00,\n            1.2394e+00, -2.5027e+00,  1.0000e+00],\n          [ 4.7002e+01,  9.6533e+00, -1.0494e+00,  3.4973e+00,  1.4124e+00,\n            1.4508e+00, -2.3927e+00,  1.0000e+00],\n          [ 3.4919e+01,  1.9135e+01, -7.2816e-01,  3.5550e+00,  1.5757e+00,\n            1.4604e+00,  2.2505e+00,  1.0000e+00],\n          [ 3.6480e+01,  3.1803e+01, -7.7215e-01,  3.1706e+00,  1.6238e+00,\n            1.5757e+00,  5.9052e-01,  1.0000e+00]]], device='cuda:0'),\n 'points': tensor([[ 0.0000, 10.1030,  1.8698, -1.6966,  0.2900],\n         [ 0.0000, 10.7480,  9.1286, -1.7959,  0.2400],\n         [ 0.0000,  6.0620,  9.8313, -1.8212,  0.3200],\n         ...,\n         [ 3.0000,  7.3879,  2.1808, -1.3720,  0.0000],\n         [ 3.0000, 22.4063, 15.3712, -0.5121,  0.1900],\n         [ 3.0000,  4.8288,  8.1506, -0.1066,  0.3800]], device='cuda:0'),\n 'use_lead_xyz': tensor([1., 1., 1., 1.], device='cuda:0'),\n 'voxels': tensor([[[10.1030,  1.8698, -1.6966,  0.2900],\n          [ 0.0000,  0.0000,  0.0000,  0.0000],\n          [ 0.0000,  0.0000,  0.0000,  0.0000],\n          [ 0.0000,  0.0000,  0.0000,  0.0000],\n          [ 0.0000,  0.0000,  0.0000,  0.0000]],\n \n         [[10.7480,  9.1286, -1.7959,  0.2400],\n          [ 0.0000,  0.0000,  0.0000,  0.0000],\n          [ 0.0000,  0.0000,  0.0000,  0.0000],\n          [ 0.0000,  0.0000,  0.0000,  0.0000],\n          [ 0.0000,  0.0000,  0.0000,  0.0000]],\n \n         [[ 6.0620,  9.8313, -1.8212,  0.3200],\n          [ 0.0000,  0.0000,  0.0000,  0.0000],\n          [ 0.0000,  0.0000,  0.0000,  0.0000],\n          [ 0.0000,  0.0000,  0.0000,  0.0000],\n          [ 0.0000,  0.0000,  0.0000,  0.0000]],\n \n         ...,\n \n         [[18.2035,  9.2764, -1.4460,  0.1800],\n          [ 0.0000,  0.0000,  0.0000,  0.0000],\n          [ 0.0000,  0.0000,  0.0000,  0.0000],\n          [ 0.0000,  0.0000,  0.0000,  0.0000],\n          [ 0.0000,  0.0000,  0.0000,  0.0000]],\n \n         [[22.4063, 15.3712, -0.5121,  0.1900],\n          [ 0.0000,  0.0000,  0.0000,  0.0000],\n          [ 0.0000,  0.0000,  0.0000,  0.0000],\n          [ 0.0000,  0.0000,  0.0000,  0.0000],\n          [ 0.0000,  0.0000,  0.0000,  0.0000]],\n \n         [[ 4.8288,  8.1506, -0.1066,  0.3800],\n          [ 0.0000,  0.0000,  0.0000,  0.0000],\n          [ 0.0000,  0.0000,  0.0000,  0.0000],\n          [ 0.0000,  0.0000,  0.0000,  0.0000],\n          [ 0.0000,  0.0000,  0.0000,  0.0000]]], device='cuda:0'),\n 'voxel_coords': tensor([[   0.,   13.,  837.,  202.],\n         [   0.,   12.,  982.,  214.],\n         [   0.,   11.,  996.,  121.],\n         ...,\n         [   3.,   15.,  985.,  364.],\n         [   3.,   24., 1107.,  448.],\n         [   3.,   28.,  963.,   96.]], device='cuda:0'),\n 'voxel_num_points': tensor([1., 1., 1.,  ..., 1., 1., 1.], device='cuda:0'),\n 'image_shape': tensor([[ 375, 1242,    3],\n         [ 375, 1242,    3],\n         [ 375, 1242,    3],\n         [ 375, 1242,    3]], device='cuda:0', dtype=torch.int32),\n 'batch_size': 4}"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from basic.utils.common_utils import put_data_to_gpu\n",
    "# 取一批数据用于模块测试\n",
    "for data in dataloader:\n",
    "    test_data = data\n",
    "    break\n",
    "# 单独把某些数据放在GPU中，注意frame_id这种还是为np.ndarray\n",
    "test_data = put_data_to_gpu(test_data)\n",
    "print(f\"input voxels shape:\", test_data['voxels'].shape)\n",
    "test_data"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Model cfg\n",
    "最终的目的是想用字符文档生成模型。但是下面只是单一测试每一个模块\n",
    "- model cfg 中包含各个模块的配置：module cfg\n",
    "- 在模型全局中使用model_info_dict记录一些必要的模型信息\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'DATASET_CONFIG': {'CONFIG_PATH': '/home/ph/Desktop/PointCloud/utils_my/kitti/cfg/kitti_dataset.yaml',\n",
      "                    'DATASET': 'KittiDataset',\n",
      "                    'DATA_AUGMENTOR': {'AUG_CONFIG_LIST': [{'DATABASE_WITH_FAKELIDAR': False,\n",
      "                                                            'DB_INFO_PATH': ['db_infos_train.pkl'],\n",
      "                                                            'LIMIT_WHOLE_SCENE': True,\n",
      "                                                            'NAME': 'gt_sampling',\n",
      "                                                            'NUM_POINT_FEATURES': 4,\n",
      "                                                            'PREPARE': {'filter_by_difficulty': [-1],\n",
      "                                                                        'filter_by_min_points': ['Car:5',\n",
      "                                                                                                 'Pedestrian:5',\n",
      "                                                                                                 'Cyclist:5']},\n",
      "                                                            'REMOVE_EXTRA_WIDTH': [0.0,\n",
      "                                                                                   0.0,\n",
      "                                                                                   0.0],\n",
      "                                                            'SAMPLE_GROUPS': ['Car:20',\n",
      "                                                                              'Pedestrian:15',\n",
      "                                                                              'Cyclist:15'],\n",
      "                                                            'USE_ROAD_PLANE': False},\n",
      "                                                           {'ALONG_AXIS_LIST': ['x'],\n",
      "                                                            'NAME': 'random_world_flip'},\n",
      "                                                           {'NAME': 'random_world_rotation',\n",
      "                                                            'WORLD_ROT_ANGLE': [-0.78539816,\n",
      "                                                                                0.78539816]},\n",
      "                                                           {'NAME': 'random_world_scaling',\n",
      "                                                            'WORLD_SCALE_RANGE': [0.95,\n",
      "                                                                                  1.05]}],\n",
      "                                       'DISABLE_AUG_LIST': ['placeholder'],\n",
      "                                       'RESERVED_FEATURE': ['frame_id',\n",
      "                                                            'points',\n",
      "                                                            'gt_boxes',\n",
      "                                                            'gt_names']},\n",
      "                    'DATA_PATH': '/home/ph/Dataset/KITTI',\n",
      "                    'DATA_PROCESSOR': [{'NAME': 'filter_points_and_boxes_inside_range',\n",
      "                                        'REMOVE_OUTSIDE_BOXES': True},\n",
      "                                       {'NAME': 'shuffle_points',\n",
      "                                        'SHUFFLE_ENABLED': {'test': False,\n",
      "                                                            'train': True}},\n",
      "                                       {'FULL_MEAN': False,\n",
      "                                        'MAX_NUMBER_OF_VOXELS': {'test': 40000,\n",
      "                                                                 'train': 16000},\n",
      "                                        'MAX_POINTS_PER_VOXEL': 5,\n",
      "                                        'NAME': 'transform_points_to_voxels',\n",
      "                                        'VOXEL_SIZE': [0.05, 0.05, 0.1]}],\n",
      "                    'DATA_SPLIT': {'test': 'val', 'train': 'train'},\n",
      "                    'FOV_POINTS_ONLY': True,\n",
      "                    'FOV_VIEW_POINTS': True,\n",
      "                    'GET_ITEM_LIST': ['points'],\n",
      "                    'INFO_PATH': {'test': ['infos_val.pkl'],\n",
      "                                  'train': ['infos_train.pkl']},\n",
      "                    'POINT_CLOUD_RANGE': [0, -40, -3, 70.4, 40, 1],\n",
      "                    'POINT_FEATURE_ENCODING': {'encoding_type': 'absolute_coordinates_encoding',\n",
      "                                               'src_feature_list': ['x',\n",
      "                                                                    'y',\n",
      "                                                                    'z',\n",
      "                                                                    'intensity'],\n",
      "                                               'used_feature_list': ['x',\n",
      "                                                                     'y',\n",
      "                                                                     'z',\n",
      "                                                                     'intensity']}},\n",
      " 'MODEL': {'BACKBONE2D': {'LAYER_NUMS': [5, 5],\n",
      "                          'LAYER_STRIDES': [1, 2],\n",
      "                          'NAME': 'BaseBEVBackbone',\n",
      "                          'NUM_FILTERS': [128, 256],\n",
      "                          'NUM_UPSAMPLE_FILTERS': [256, 256],\n",
      "                          'UPSAMPLE_STRIDES': [1, 2]},\n",
      "           'BACKBONE3D': {'DOWN_SAMPLE_RATE': 8, 'NAME': 'VoxelBackBone8x'},\n",
      "           'DENSE_HEAD': {'ANCHOR_GENERATOR_CONFIG': {'CLASS_CONFIG': [{'anchor_dims': 3,\n",
      "                                                                        'boxes_size': [[3.9,\n",
      "                                                                                        1.6,\n",
      "                                                                                        1.56]],\n",
      "                                                                        'center_aligned': True,\n",
      "                                                                        'class_name': 'Car',\n",
      "                                                                        'mode': 'Range',\n",
      "                                                                        'ratios': [1],\n",
      "                                                                        'road_plane_aligned': True,\n",
      "                                                                        'road_plane_height': -1.2,\n",
      "                                                                        'rotations': [0,\n",
      "                                                                                      1.57]},\n",
      "                                                                       {'anchor_dims': 3,\n",
      "                                                                        'boxes_size': [[0.8,\n",
      "                                                                                        0.6,\n",
      "                                                                                        1.73]],\n",
      "                                                                        'center_aligned': True,\n",
      "                                                                        'class_name': 'Pedestrian',\n",
      "                                                                        'mode': 'Range',\n",
      "                                                                        'ratios': [1],\n",
      "                                                                        'road_plane_aligned': True,\n",
      "                                                                        'road_plane_height': -1.2,\n",
      "                                                                        'rotations': [0,\n",
      "                                                                                      1.57]},\n",
      "                                                                       {'anchor_bottom_heights': [-0.6],\n",
      "                                                                        'anchor_dims': 3,\n",
      "                                                                        'boxes_size': [[1.76,\n",
      "                                                                                        0.6,\n",
      "                                                                                        1.73]],\n",
      "                                                                        'center_aligned': True,\n",
      "                                                                        'class_name': 'Cyclist',\n",
      "                                                                        'mode': 'Range',\n",
      "                                                                        'ratios': [1],\n",
      "                                                                        'road_plane_aligned': True,\n",
      "                                                                        'road_plane_height': -1.2,\n",
      "                                                                        'rotations': [0,\n",
      "                                                                                      1.57]}],\n",
      "                                                      'DEVICE': 'cuda',\n",
      "                                                      'NAME': 'AnchorGenerator'},\n",
      "                          'LOSS_CONFIG': {'CLS_LOSS': {'NAME': 'FocalLoss',\n",
      "                                                       'alpha': 0.25,\n",
      "                                                       'gamma': 2},\n",
      "                                          'LOSS_WEIGHTS': {'cls_weight': 1.0,\n",
      "                                                           'code_weights': [1.0,\n",
      "                                                                            1.0,\n",
      "                                                                            1.0,\n",
      "                                                                            1.0,\n",
      "                                                                            1.0,\n",
      "                                                                            1.0,\n",
      "                                                                            1.0],\n",
      "                                                           'dir_weight': 0.2,\n",
      "                                                           'reg_weight': 2.0},\n",
      "                                          'REG_LOSS': {'NAME': 'SmoothL1Loss',\n",
      "                                                       'beta': 0.5}},\n",
      "                          'NAME': 'AnchorHead',\n",
      "                          'TARGET_ASSIGNER_CONFIG': {'BOX_ENCODER': {'NAME': 'ResidualCoder',\n",
      "                                                                     'code_size': 7,\n",
      "                                                                     'encode_angle_by_sincos': False},\n",
      "                                                     'CLASS_THRESHOLD': [{'class_name': 'Car',\n",
      "                                                                          'neg_threshold': 0.45,\n",
      "                                                                          'pos_threshold': 0.5},\n",
      "                                                                         {'class_name': 'Pedestrian',\n",
      "                                                                          'neg_threshold': 0.35,\n",
      "                                                                          'pos_threshold': 0.5},\n",
      "                                                                         {'class_name': 'Cyclist',\n",
      "                                                                          'neg_threshold': 0.35,\n",
      "                                                                          'pos_threshold': 0.5}],\n",
      "                                                     'DEVICE': 'cuda',\n",
      "                                                     'IOU_CALCULATOR': {'NAME': 'Iou3DCalculator'},\n",
      "                                                     'MATCH_HEIGHT': False,\n",
      "                                                     'NAME': 'MaxIouTargetAssigner',\n",
      "                                                     'NORM_BY_NUM_EXAMPLES': False,\n",
      "                                                     'POS_FRACTION': -1.0,\n",
      "                                                     'SAMPLER': {'NAME': 'MaxSizeSubSampler',\n",
      "                                                                 'sample_size': 512}}},\n",
      "           'FEATURE_EXTRACTOR': {'NAME': 'MeanVFE'},\n",
      "           'NAME': 'SECONDNet',\n",
      "           'NECK': {'DIM': 2,\n",
      "                    'NAME': 'DimCompression',\n",
      "                    'OUTPUT_FEATURE_DIMS': 256},\n",
      "           'POST_PROCESSING': {'EVAL_METRIC': 'kitti',\n",
      "                               'NMS_CONFIG': {'MULTI_CLASSES_NMS': False,\n",
      "                                              'NMS_POST_MAXSIZE': 500,\n",
      "                                              'NMS_PRE_MAXSIZE': 4096,\n",
      "                                              'NMS_THRESH': 0.01,\n",
      "                                              'NMS_TYPE': 'nms_gpu'},\n",
      "                               'OUTPUT_RAW_SCORE': False,\n",
      "                               'RECALL_THRESH_LIST': [0.3, 0.5, 0.7],\n",
      "                               'SCORE_THRESH': 0.1}},\n",
      " 'OPTIMIZATION': {'BATCH_SIZE_PER_GPU': 4,\n",
      "                  'DECAY_STEP_LIST': [35, 45],\n",
      "                  'DIV_FACTOR': 10,\n",
      "                  'GRAD_NORM_CLIP': 10,\n",
      "                  'LR': 0.003,\n",
      "                  'LR_CLIP': 1e-07,\n",
      "                  'LR_DECAY': 0.1,\n",
      "                  'LR_WARMUP': False,\n",
      "                  'MOMENTUM': 0.9,\n",
      "                  'MOMS': [0.95, 0.85],\n",
      "                  'NUM_EPOCHS': 80,\n",
      "                  'OPTIMIZER': 'adam_onecycle',\n",
      "                  'PCT_START': 0.4,\n",
      "                  'WARMUP_EPOCH': 1,\n",
      "                  'WEIGHT_DECAY': 0.01},\n",
      " 'PERPRO_CONFIG': {'CONFIG_PATH': '/home/ph/Desktop/PointCloud/utils_my/kitti/cfg/preprocess_cfg.yaml',\n",
      "                   'CREATE_GT_DATABASE': {'FLAG': True,\n",
      "                                          'USED_CLASSES': ['Car',\n",
      "                                                           'Pedestrian',\n",
      "                                                           'Cyclist']},\n",
      "                   'DATA_ROOT': '/home/ph/Dataset/KITTI',\n",
      "                   'DUMP_INTERVAL': 1000,\n",
      "                   'SAVE_ROOT': '/home/ph/Dataset/KITTI/infos',\n",
      "                   'WORKER_NUM': 4}}\n"
     ]
    }
   ],
   "source": [
    "from pprint import pprint\n",
    "from basic.utils.config_utils import cfg_from_yaml_file\n",
    "model_cfg = cfg_from_yaml_file('../basic/model/model_cfg/second.yaml')\n",
    "model_info_dict = {\n",
    "    'module_list': [],\n",
    "    'training': True,\n",
    "}\n",
    "data_infos = dataloader.dataset.get_data_infos()\n",
    "model_info_dict.update(data_infos)\n",
    "pprint(model_cfg)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "初始模型信息，注意经过每一个模块处理后,更新以下信息。\n",
    "- 更新module_list记录的模块\n",
    "- 当前特征图中每个点的特征维度\n",
    "- 后面模块可能会使用到的当前模块的一些信息"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "module_list:[]\n",
      "training:True\n",
      "raw_point_feature_dims:4\n",
      "cur_point_feature_dims:4\n",
      "point_cloud_range:[  0.  -40.   -3.   70.4  40.    1. ]\n",
      "voxel_size:[0.05, 0.05, 0.1]\n",
      "grid_size:[1408 1600   40]\n",
      "class_names:['Car']\n"
     ]
    }
   ],
   "source": [
    "for key, value in model_info_dict.items():\n",
    "    print(f\"{key}:{value}\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Feature Extractor/Encoding Module\n",
    "点云特征提取模块目的是：从无序的原始点云数据中提取出有序的初步特征,或者说找到一种方式编码原始点云，\n",
    "令其有序。其实就是把原始点云转换为有序的张量矩阵\n",
    "常见PointNet的方式，就是为了提取有序的初步特征；而体素的方式，是为了用体素这种格式编码原始点云，令其有序\n",
    "为什么要这样做？我的理解是，现有CNN只能处理有序的张量！！！不管是3d卷积还是2d卷积\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Voxel Feature Extractor(VFE)\n",
    "- 提取体素级别的特征\n",
    "输入：体素，以及体素相关的信息\n",
    "输出：提取的体素特征\n",
    "- Mean VFE：取每个体素内所有点的平均值作为输出特征\n",
    "- MLP VFE:对每个体素内的点集，做类似PointNet的操作。即用MLP + Max pooling 提取点集的特征"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean VFE： voxel_features shape: torch.Size([63662, 4])\n"
     ]
    }
   ],
   "source": [
    "#mean vfe\n",
    "from basic.module.feature_extractor import MeanVFE\n",
    "mean_vfe_module = MeanVFE(model_cfg, model_info_dict).cuda()\n",
    "output = mean_vfe_module(test_data)\n",
    "model_info_dict['cur_point_feature_dims'] = mean_vfe_module.output_feature_dims\n",
    "model_info_dict['module_list'].append(mean_vfe_module)\n",
    "print(f\"Mean VFE： voxel_features shape:\", output['voxel_features'].shape)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current model infos:\n",
      "module_list:[MeanVFE()]\n",
      "training:True\n",
      "raw_point_feature_dims:4\n",
      "cur_point_feature_dims:4\n",
      "point_cloud_range:[  0.  -40.   -3.   70.4  40.    1. ]\n",
      "voxel_size:[0.05, 0.05, 0.1]\n",
      "grid_size:[1408 1600   40]\n",
      "class_names:['Car']\n"
     ]
    }
   ],
   "source": [
    "print(f\"current model infos:\")\n",
    "for key, value in model_info_dict.items():\n",
    "    print(f\"{key}:{value}\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mlp VFE： voxel_features shape: torch.Size([63662, 128])\n"
     ]
    }
   ],
   "source": [
    "# mlp vfe just test\n",
    "from basic.module.feature_extractor import MlpVFE\n",
    "\n",
    "cfg = {'mlp_dims': [32, 64, 64, 128, 128],\n",
    "       'input_channels': 4}\n",
    "mlp_vfe_module = MlpVFE(cfg).cuda()\n",
    "t = mlp_vfe_module(test_data)\n",
    "print(f\"Mlp VFE： voxel_features shape:\", t.shape)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Point Feature Extractor(PFE)\n",
    "- 直接提取原始点云的特征\n",
    "- 代表方法PointNet++的SetAbstract layer"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "#todo"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Backbone3D\n",
    "- 经过原始点云的特征提取/编码后，一般会得到B,C,VH,VW,VD的体素张量特征矩阵。或B,C,H,W的点云特征张量矩阵。\n",
    "根据特征张量维度选择用3D卷积还是2D卷积网络来进一步提取特征。\n",
    "- 因为体素张量特征矩阵非常稀疏，多使用稀疏卷积。使用spconv库来进行稀疏3D卷积"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "spconv_tensor_shape: torch.Size([4, 128, 2, 200, 176])\n"
     ]
    }
   ],
   "source": [
    "from basic.module.backbone3d import VoxelBackBone8x\n",
    "\n",
    "back3d_cfg = model_cfg.MODEL.BACKBONE3D\n",
    "backbone3d_module = VoxelBackBone8x(back3d_cfg, model_info_dict).cuda()\n",
    "output = backbone3d_module(output)\n",
    "print(f\"spconv_tensor_shape:\", output['encoded_spconv_tensor'].dense().shape)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "model_info_dict['module_list'].append(backbone3d_module)\n",
    "model_info_dict['cur_point_feature_dims'] = backbone3d_module.output_feature_dims\n",
    "model_info_dict['feature_map_size'] = backbone3d_module.output_feature_size\n",
    "model_info_dict['backbone_channels'] = backbone3d_module.backbone_channels\\\n",
    "    if hasattr(backbone3d_module, 'backbone_channels') else None"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current model infos:\n",
      "module_list:[MeanVFE(), VoxelBackBone8x(\n",
      "  (conv_input): SparseSequential(\n",
      "    (0): SubMConv3d()\n",
      "    (1): BatchNorm1d(16, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "    (2): ReLU()\n",
      "  )\n",
      "  (conv1): SparseSequential(\n",
      "    (0): SparseSequential(\n",
      "      (0): SubMConv3d()\n",
      "      (1): BatchNorm1d(16, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "      (2): ReLU()\n",
      "    )\n",
      "  )\n",
      "  (conv2): SparseSequential(\n",
      "    (0): SparseSequential(\n",
      "      (0): SparseConv3d()\n",
      "      (1): BatchNorm1d(32, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "      (2): ReLU()\n",
      "    )\n",
      "    (1): SparseSequential(\n",
      "      (0): SubMConv3d()\n",
      "      (1): BatchNorm1d(32, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "      (2): ReLU()\n",
      "    )\n",
      "    (2): SparseSequential(\n",
      "      (0): SubMConv3d()\n",
      "      (1): BatchNorm1d(32, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "      (2): ReLU()\n",
      "    )\n",
      "  )\n",
      "  (conv3): SparseSequential(\n",
      "    (0): SparseSequential(\n",
      "      (0): SparseConv3d()\n",
      "      (1): BatchNorm1d(64, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "      (2): ReLU()\n",
      "    )\n",
      "    (1): SparseSequential(\n",
      "      (0): SubMConv3d()\n",
      "      (1): BatchNorm1d(64, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "      (2): ReLU()\n",
      "    )\n",
      "    (2): SparseSequential(\n",
      "      (0): SubMConv3d()\n",
      "      (1): BatchNorm1d(64, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "      (2): ReLU()\n",
      "    )\n",
      "  )\n",
      "  (conv4): SparseSequential(\n",
      "    (0): SparseSequential(\n",
      "      (0): SparseConv3d()\n",
      "      (1): BatchNorm1d(64, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "      (2): ReLU()\n",
      "    )\n",
      "    (1): SparseSequential(\n",
      "      (0): SubMConv3d()\n",
      "      (1): BatchNorm1d(64, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "      (2): ReLU()\n",
      "    )\n",
      "    (2): SparseSequential(\n",
      "      (0): SubMConv3d()\n",
      "      (1): BatchNorm1d(64, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "      (2): ReLU()\n",
      "    )\n",
      "  )\n",
      "  (conv_out): SparseSequential(\n",
      "    (0): SparseConv3d()\n",
      "    (1): BatchNorm1d(128, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "    (2): ReLU()\n",
      "  )\n",
      ")]\n",
      "training:True\n",
      "raw_point_feature_dims:4\n",
      "cur_point_feature_dims:128\n",
      "point_cloud_range:[  0.  -40.   -3.   70.4  40.    1. ]\n",
      "voxel_size:[0.05, 0.05, 0.1]\n",
      "grid_size:[1408 1600   40]\n",
      "class_names:['Car']\n",
      "feature_map_size:[  2 200 176]\n",
      "backbone_channels:{'x_conv1': 16, 'x_conv2': 32, 'x_conv3': 64, 'x_conv4': 64}\n"
     ]
    }
   ],
   "source": [
    "print(f\"current model infos:\")\n",
    "for key, value in model_info_dict.items():\n",
    "    print(f\"{key}:{value}\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# NECK\n",
    "BackBone3D提取的特征向量依然处于3维空间内。目前一般不会在3维空间内提取ROIs。因为3DNMS，3DIOU等都很麻烦....。\n",
    "因此直接在前视图FOV或在鸟瞰图BEV上提取ROIs。为此需要将3d特征转换为2d特征。\n",
    "- 常用的Neck：\n",
    "直接压缩：比如将B,C,D,H,W的特征压缩为B，C*H，D,W,此时的特征图可以认为是BEV视角下的二维特征图"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "直接压缩 torch.Size([4, 256, 200, 176])\n"
     ]
    }
   ],
   "source": [
    "from basic.module.neck import DimCompression\n",
    "\n",
    "neck_cfg = model_cfg.MODEL.NECK\n",
    "neck_module = DimCompression(module_cfg=neck_cfg, model_info_dict=model_info_dict)\n",
    "output = neck_module(output)\n",
    "print(\"直接压缩\", output['spatial_features'].shape)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [
    "model_info_dict['module_list'].append(neck_module)\n",
    "model_info_dict['cur_point_feature_dims'] = neck_module.output_feature_dims\n",
    "model_info_dict['feature_map_size'] = neck_module.output_feature_size"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current model infos:\n",
      "module_list:[MeanVFE(), VoxelBackBone8x(\n",
      "  (conv_input): SparseSequential(\n",
      "    (0): SubMConv3d()\n",
      "    (1): BatchNorm1d(16, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "    (2): ReLU()\n",
      "  )\n",
      "  (conv1): SparseSequential(\n",
      "    (0): SparseSequential(\n",
      "      (0): SubMConv3d()\n",
      "      (1): BatchNorm1d(16, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "      (2): ReLU()\n",
      "    )\n",
      "  )\n",
      "  (conv2): SparseSequential(\n",
      "    (0): SparseSequential(\n",
      "      (0): SparseConv3d()\n",
      "      (1): BatchNorm1d(32, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "      (2): ReLU()\n",
      "    )\n",
      "    (1): SparseSequential(\n",
      "      (0): SubMConv3d()\n",
      "      (1): BatchNorm1d(32, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "      (2): ReLU()\n",
      "    )\n",
      "    (2): SparseSequential(\n",
      "      (0): SubMConv3d()\n",
      "      (1): BatchNorm1d(32, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "      (2): ReLU()\n",
      "    )\n",
      "  )\n",
      "  (conv3): SparseSequential(\n",
      "    (0): SparseSequential(\n",
      "      (0): SparseConv3d()\n",
      "      (1): BatchNorm1d(64, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "      (2): ReLU()\n",
      "    )\n",
      "    (1): SparseSequential(\n",
      "      (0): SubMConv3d()\n",
      "      (1): BatchNorm1d(64, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "      (2): ReLU()\n",
      "    )\n",
      "    (2): SparseSequential(\n",
      "      (0): SubMConv3d()\n",
      "      (1): BatchNorm1d(64, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "      (2): ReLU()\n",
      "    )\n",
      "  )\n",
      "  (conv4): SparseSequential(\n",
      "    (0): SparseSequential(\n",
      "      (0): SparseConv3d()\n",
      "      (1): BatchNorm1d(64, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "      (2): ReLU()\n",
      "    )\n",
      "    (1): SparseSequential(\n",
      "      (0): SubMConv3d()\n",
      "      (1): BatchNorm1d(64, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "      (2): ReLU()\n",
      "    )\n",
      "    (2): SparseSequential(\n",
      "      (0): SubMConv3d()\n",
      "      (1): BatchNorm1d(64, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "      (2): ReLU()\n",
      "    )\n",
      "  )\n",
      "  (conv_out): SparseSequential(\n",
      "    (0): SparseConv3d()\n",
      "    (1): BatchNorm1d(128, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "    (2): ReLU()\n",
      "  )\n",
      "), DimCompression()]\n",
      "training:True\n",
      "raw_point_feature_dims:4\n",
      "cur_point_feature_dims:256\n",
      "point_cloud_range:[  0.  -40.   -3.   70.4  40.    1. ]\n",
      "voxel_size:[0.05, 0.05, 0.1]\n",
      "grid_size:[1408 1600   40]\n",
      "class_names:['Car']\n",
      "feature_map_size:[  1 200 176]\n",
      "backbone_channels:{'x_conv1': 16, 'x_conv2': 32, 'x_conv3': 64, 'x_conv4': 64}\n"
     ]
    }
   ],
   "source": [
    "print(f\"current model infos:\")\n",
    "for key, value in model_info_dict.items():\n",
    "    print(f\"{key}:{value}\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Backbone2D\n",
    "与BackBone3D一样，根据输入的张量维度。选择用2D卷积网络提取特征。通常如果使用NECK 模块将3维空间内的特征压缩为2维空间的特征后\n",
    "也会再次使用2D的卷积网络再次提取特征。"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [],
   "source": [
    "# from basic.module.backbone2d import BEVExtractor\n",
    "# conv_channels = [32, 64, 128, 256]\n",
    "# conv_kernel = [2, 2, 3, 3]\n",
    "# backbone2d = BEVExtractor(128, conv_channels, conv_kernel)\n",
    "# output = backbone2d(output)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "data": {
      "text/plain": "torch.Size([4, 512, 200, 176])"
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from basic.module.backbone2d.base_bev_backbone import BaseBEVBackbone\n",
    "\n",
    "backbone2d_cfg = model_cfg.MODEL.BACKBONE2D\n",
    "backbone2d = BaseBEVBackbone(backbone2d_cfg, model_info_dict).cuda()\n",
    "output = backbone2d(output)\n",
    "output['spatial_features_2d'].shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [],
   "source": [
    "model_info_dict['module_list'].append(backbone2d)\n",
    "model_info_dict['cur_point_feature_dims'] = backbone2d.output_feature_dims"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current model infos:\n",
      "module_list:[MeanVFE(), VoxelBackBone8x(\n",
      "  (conv_input): SparseSequential(\n",
      "    (0): SubMConv3d()\n",
      "    (1): BatchNorm1d(16, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "    (2): ReLU()\n",
      "  )\n",
      "  (conv1): SparseSequential(\n",
      "    (0): SparseSequential(\n",
      "      (0): SubMConv3d()\n",
      "      (1): BatchNorm1d(16, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "      (2): ReLU()\n",
      "    )\n",
      "  )\n",
      "  (conv2): SparseSequential(\n",
      "    (0): SparseSequential(\n",
      "      (0): SparseConv3d()\n",
      "      (1): BatchNorm1d(32, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "      (2): ReLU()\n",
      "    )\n",
      "    (1): SparseSequential(\n",
      "      (0): SubMConv3d()\n",
      "      (1): BatchNorm1d(32, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "      (2): ReLU()\n",
      "    )\n",
      "    (2): SparseSequential(\n",
      "      (0): SubMConv3d()\n",
      "      (1): BatchNorm1d(32, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "      (2): ReLU()\n",
      "    )\n",
      "  )\n",
      "  (conv3): SparseSequential(\n",
      "    (0): SparseSequential(\n",
      "      (0): SparseConv3d()\n",
      "      (1): BatchNorm1d(64, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "      (2): ReLU()\n",
      "    )\n",
      "    (1): SparseSequential(\n",
      "      (0): SubMConv3d()\n",
      "      (1): BatchNorm1d(64, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "      (2): ReLU()\n",
      "    )\n",
      "    (2): SparseSequential(\n",
      "      (0): SubMConv3d()\n",
      "      (1): BatchNorm1d(64, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "      (2): ReLU()\n",
      "    )\n",
      "  )\n",
      "  (conv4): SparseSequential(\n",
      "    (0): SparseSequential(\n",
      "      (0): SparseConv3d()\n",
      "      (1): BatchNorm1d(64, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "      (2): ReLU()\n",
      "    )\n",
      "    (1): SparseSequential(\n",
      "      (0): SubMConv3d()\n",
      "      (1): BatchNorm1d(64, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "      (2): ReLU()\n",
      "    )\n",
      "    (2): SparseSequential(\n",
      "      (0): SubMConv3d()\n",
      "      (1): BatchNorm1d(64, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "      (2): ReLU()\n",
      "    )\n",
      "  )\n",
      "  (conv_out): SparseSequential(\n",
      "    (0): SparseConv3d()\n",
      "    (1): BatchNorm1d(128, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "    (2): ReLU()\n",
      "  )\n",
      "), DimCompression(), BaseBEVBackbone(\n",
      "  (blocks): ModuleList(\n",
      "    (0): Sequential(\n",
      "      (0): ZeroPad2d(padding=(1, 1, 1, 1), value=0.0)\n",
      "      (1): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
      "      (2): BatchNorm2d(128, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "      (3): ReLU()\n",
      "      (4): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (5): BatchNorm2d(128, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "      (6): ReLU()\n",
      "      (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (8): BatchNorm2d(128, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "      (9): ReLU()\n",
      "      (10): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (11): BatchNorm2d(128, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "      (12): ReLU()\n",
      "      (13): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (14): BatchNorm2d(128, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "      (15): ReLU()\n",
      "      (16): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (17): BatchNorm2d(128, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "      (18): ReLU()\n",
      "    )\n",
      "    (1): Sequential(\n",
      "      (0): ZeroPad2d(padding=(1, 1, 1, 1), value=0.0)\n",
      "      (1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
      "      (2): BatchNorm2d(256, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "      (3): ReLU()\n",
      "      (4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (5): BatchNorm2d(256, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "      (6): ReLU()\n",
      "      (7): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (8): BatchNorm2d(256, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "      (9): ReLU()\n",
      "      (10): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (11): BatchNorm2d(256, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "      (12): ReLU()\n",
      "      (13): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (14): BatchNorm2d(256, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "      (15): ReLU()\n",
      "      (16): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (17): BatchNorm2d(256, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "      (18): ReLU()\n",
      "    )\n",
      "  )\n",
      "  (deblocks): ModuleList(\n",
      "    (0): Sequential(\n",
      "      (0): ConvTranspose2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (1): BatchNorm2d(256, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "      (2): ReLU()\n",
      "    )\n",
      "    (1): Sequential(\n",
      "      (0): ConvTranspose2d(256, 256, kernel_size=(2, 2), stride=(2, 2), bias=False)\n",
      "      (1): BatchNorm2d(256, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "      (2): ReLU()\n",
      "    )\n",
      "  )\n",
      ")]\n",
      "training:True\n",
      "raw_point_feature_dims:4\n",
      "cur_point_feature_dims:512\n",
      "point_cloud_range:[  0.  -40.   -3.   70.4  40.    1. ]\n",
      "voxel_size:[0.05, 0.05, 0.1]\n",
      "grid_size:[1408 1600   40]\n",
      "class_names:['Car']\n",
      "feature_map_size:[  1 200 176]\n",
      "backbone_channels:{'x_conv1': 16, 'x_conv2': 32, 'x_conv3': 64, 'x_conv4': 64}\n"
     ]
    }
   ],
   "source": [
    "print(f\"current model infos:\")\n",
    "for key, value in model_info_dict.items():\n",
    "    print(f\"{key}:{value}\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "截止目前为止：输入点云的shape变化为\n",
    "- 原始点云->体素：183149, 5, 4\n",
    "- VFE：183149, 4\n",
    "- BackBone3D：12， 128， 2， 200， 176\n",
    "- neck：12，256，200，176\n",
    "- BackBone2D：12，256，200，176，shape未变因为卷积过后，又转置卷积回了原始大小\n",
    "经过上面的各个模块，从原始点云中获取了能代表该点云的二维特征图。接下来是3D目标识别中最重要的部分：Dense Head 与 ROI head。"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Dense Head\n",
    "BackBone2D的输出为用于Bbox回归的，和Bbox分类的两个likelihood矩阵"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "anchor generator（一）\n",
    "- 枚举7种anchor可能用到的特征，即x，y，z，h，w，l，r。然后通过mesh gird产生所有anchors。其中根据anchor中心坐标xyz的取法不同又分为Range和Stride两种方案\n",
    "    - Range：在点云范围内，给定每个轴的取值范围。每个轴按照特征图中对应的维度平均划分这些轴。比如特征图对应X轴的维度大小为176，就在X轴范围内平均划分176个。\n",
    "    - Stride：给定xyz坐标下的原点坐标，分别以x stride，y stride，z stride沿着各个轴的正方向按步长获得anchor中心坐标xyz。\n",
    "    - 代码接口虽然可以自定义Range和Stride。但是为了将特征图上的每个特征点与原图上的每个anchor关联起来，一定要平均划分！！即Range取值为点云的范围，而Stride取值为\n",
    "  点云采样范围 / 特征图大小。即\\[z_stride, x_stride, y_stride\\]=\\[z_len, x_len, y_len\\] / \\[H, W, L\\]。这样看按Range还是Stride的方案取得的结果应该差距不大。。。\n",
    "    - 实际上就是把特征图上的每个特征点，映射回了原始数据上对应区域的中心？假如原始点云下采样了8倍得到特征图，则特征图中\\[0,0,0\\]点对应原点云（点云原点坐标为000）中以\\[8,8,8\\]为中心，边长为8的正方形区域？"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [
    {
     "data": {
      "text/plain": "({'NAME': 'AnchorGenerator',\n  'DEVICE': 'cuda',\n  'CLASS_CONFIG': [{'class_name': 'Car',\n    'mode': 'Range',\n    'anchor_dims': 3,\n    'boxes_size': [[3.9, 1.6, 1.56]],\n    'rotations': [0, 1.57],\n    'ratios': [1],\n    'center_aligned': True,\n    'road_plane_aligned': True,\n    'road_plane_height': -1.2},\n   {'class_name': 'Pedestrian',\n    'mode': 'Range',\n    'anchor_dims': 3,\n    'boxes_size': [[0.8, 0.6, 1.73]],\n    'rotations': [0, 1.57],\n    'ratios': [1],\n    'center_aligned': True,\n    'road_plane_aligned': True,\n    'road_plane_height': -1.2},\n   {'class_name': 'Cyclist',\n    'mode': 'Range',\n    'anchor_dims': 3,\n    'boxes_size': [[1.76, 0.6, 1.73]],\n    'rotations': [0, 1.57],\n    'ratios': [1],\n    'center_aligned': True,\n    'anchor_bottom_heights': [-0.6],\n    'road_plane_aligned': True,\n    'road_plane_height': -1.2}]},\n {'module_list': [MeanVFE(),\n   VoxelBackBone8x(\n     (conv_input): SparseSequential(\n       (0): SubMConv3d()\n       (1): BatchNorm1d(16, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n       (2): ReLU()\n     )\n     (conv1): SparseSequential(\n       (0): SparseSequential(\n         (0): SubMConv3d()\n         (1): BatchNorm1d(16, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n         (2): ReLU()\n       )\n     )\n     (conv2): SparseSequential(\n       (0): SparseSequential(\n         (0): SparseConv3d()\n         (1): BatchNorm1d(32, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n         (2): ReLU()\n       )\n       (1): SparseSequential(\n         (0): SubMConv3d()\n         (1): BatchNorm1d(32, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n         (2): ReLU()\n       )\n       (2): SparseSequential(\n         (0): SubMConv3d()\n         (1): BatchNorm1d(32, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n         (2): ReLU()\n       )\n     )\n     (conv3): SparseSequential(\n       (0): SparseSequential(\n         (0): SparseConv3d()\n         (1): BatchNorm1d(64, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n         (2): ReLU()\n       )\n       (1): SparseSequential(\n         (0): SubMConv3d()\n         (1): BatchNorm1d(64, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n         (2): ReLU()\n       )\n       (2): SparseSequential(\n         (0): SubMConv3d()\n         (1): BatchNorm1d(64, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n         (2): ReLU()\n       )\n     )\n     (conv4): SparseSequential(\n       (0): SparseSequential(\n         (0): SparseConv3d()\n         (1): BatchNorm1d(64, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n         (2): ReLU()\n       )\n       (1): SparseSequential(\n         (0): SubMConv3d()\n         (1): BatchNorm1d(64, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n         (2): ReLU()\n       )\n       (2): SparseSequential(\n         (0): SubMConv3d()\n         (1): BatchNorm1d(64, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n         (2): ReLU()\n       )\n     )\n     (conv_out): SparseSequential(\n       (0): SparseConv3d()\n       (1): BatchNorm1d(128, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n       (2): ReLU()\n     )\n   ),\n   DimCompression(),\n   BaseBEVBackbone(\n     (blocks): ModuleList(\n       (0): Sequential(\n         (0): ZeroPad2d(padding=(1, 1, 1, 1), value=0.0)\n         (1): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), bias=False)\n         (2): BatchNorm2d(128, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n         (3): ReLU()\n         (4): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n         (5): BatchNorm2d(128, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n         (6): ReLU()\n         (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n         (8): BatchNorm2d(128, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n         (9): ReLU()\n         (10): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n         (11): BatchNorm2d(128, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n         (12): ReLU()\n         (13): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n         (14): BatchNorm2d(128, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n         (15): ReLU()\n         (16): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n         (17): BatchNorm2d(128, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n         (18): ReLU()\n       )\n       (1): Sequential(\n         (0): ZeroPad2d(padding=(1, 1, 1, 1), value=0.0)\n         (1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), bias=False)\n         (2): BatchNorm2d(256, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n         (3): ReLU()\n         (4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n         (5): BatchNorm2d(256, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n         (6): ReLU()\n         (7): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n         (8): BatchNorm2d(256, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n         (9): ReLU()\n         (10): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n         (11): BatchNorm2d(256, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n         (12): ReLU()\n         (13): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n         (14): BatchNorm2d(256, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n         (15): ReLU()\n         (16): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n         (17): BatchNorm2d(256, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n         (18): ReLU()\n       )\n     )\n     (deblocks): ModuleList(\n       (0): Sequential(\n         (0): ConvTranspose2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n         (1): BatchNorm2d(256, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n         (2): ReLU()\n       )\n       (1): Sequential(\n         (0): ConvTranspose2d(256, 256, kernel_size=(2, 2), stride=(2, 2), bias=False)\n         (1): BatchNorm2d(256, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n         (2): ReLU()\n       )\n     )\n   )],\n  'training': True,\n  'raw_point_feature_dims': 4,\n  'cur_point_feature_dims': 512,\n  'point_cloud_range': array([  0. , -40. ,  -3. ,  70.4,  40. ,   1. ], dtype=float32),\n  'voxel_size': [0.05, 0.05, 0.1],\n  'grid_size': array([1408, 1600,   40]),\n  'class_names': ['Car'],\n  'feature_map_size': array([  1, 200, 176]),\n  'backbone_channels': {'x_conv1': 16,\n   'x_conv2': 32,\n   'x_conv3': 64,\n   'x_conv4': 64}})"
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# anchor generator config\n",
    "anchor_gen_cfg = model_cfg.MODEL.DENSE_HEAD.ANCHOR_GENERATOR_CONFIG\n",
    "anchor_gen_cfg, model_info_dict"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Range anchors shape: torch.Size([176, 200, 1, 1, 2, 7])\n",
      "Range stride: tensor([[[[0.4000, 0.4000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [0.4000, 0.4000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]]],\n",
      "       device='cuda:0')\n",
      "begin: tensor([[[[  0.2000, -39.8000,  -1.2000,   3.9000,   1.6000,   1.5600,   0.0000],\n",
      "          [  0.2000, -39.8000,  -1.2000,   3.9000,   1.6000,   1.5600,   1.5700]]]],\n",
      "       device='cuda:0')\n",
      "end: tensor([[[[70.2000, 39.8000, -1.2000,  3.9000,  1.6000,  1.5600,  0.0000],\n",
      "          [70.2000, 39.8000, -1.2000,  3.9000,  1.6000,  1.5600,  1.5700]]]],\n",
      "       device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "from basic.module.dense_head.anchor_generator.anchor_gen_base import AnchorGenerator\n",
    "\n",
    "anchor_generator = AnchorGenerator(anchor_gen_cfg, model_info_dict, class_type='Car', dtype=torch.float32)\n",
    "anchors = anchor_generator.gen_anchors(flatten_output=False)\n",
    "print(\"Range anchors shape:\", anchors.shape)\n",
    "print(\"Range stride:\", anchors[1, 1] - anchors[0, 0])\n",
    "print(\"begin:\", anchors[0, 0])\n",
    "print(\"end:\", anchors[-1, -1])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "stride: tensor([0.4000, 0.4000, 4.0000])\n",
      "Stride anchors shape: torch.Size([176, 200, 1, 1, 2, 7])\n",
      "begin: tensor([[[[  0.2000, -39.8000,  -1.2000,   3.9000,   1.6000,   1.5600,   0.0000],\n",
      "          [  0.2000, -39.8000,  -1.2000,   3.9000,   1.6000,   1.5600,   1.5700]]]],\n",
      "       device='cuda:0')\n",
      "end: tensor([[[[70.2000, 39.8000, -1.2000,  3.9000,  1.6000,  1.5600,  0.0000],\n",
      "          [70.2000, 39.8000, -1.2000,  3.9000,  1.6000,  1.5600,  1.5700]]]],\n",
      "       device='cuda:0')\n",
      "output anchor shape: torch.Size([70400, 7])\n"
     ]
    }
   ],
   "source": [
    "anchor_generator.set_mode('Stride')\n",
    "anchors = anchor_generator.gen_anchors(flatten_output=False)\n",
    "print(\"stride:\", anchor_generator.stride)\n",
    "print(\"Stride anchors shape:\", anchors.shape)\n",
    "print(\"begin:\", anchors[0, 0])\n",
    "print(\"end:\", anchors[-1, -1])\n",
    "final_anchors = anchors.view(-1, 7)\n",
    "print(\"output anchor shape:\", final_anchors.shape)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "1.注意输出anchors的shape为176, 200, 1, 1, 2, 7。最后一个维度代表anchor的特征向量xyzlwhr，\n",
    "其他维度分别与x y z size rot的可枚举数量一致.当然最后输出的shape为(176x200x1x1x2, 7)\n",
    "2.在对齐体素中心的情况下，Range和Stride两种方案的结果都是一样的。假如点云的x轴范围为\\[0, 70.4\\]，\n",
    "而x轴对应的维度在特征图上大小为176.则均分后相邻点的距离为70.4 / 176 = 0.4。Range和Stride\n",
    "枚举X坐标的核心代码如下"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [],
   "source": [
    "ranges = torch.linspace(0, 70.4, 176)\n",
    "range_align_center = torch.linspace(0 + 0.2, 70.4 - 0.2, 176)\n",
    "stride = torch.arange(0, 176) * 0.4\n",
    "stride_align_center = stride + 0.4 / 2"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [],
   "source": [
    "anchor_generator.set_mode('Range')\n",
    "model_info_dict['raw_anchor_shape'] = anchor_generator.shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "随机绘制100个anchor box看看\n",
    "- 明显anchor 产生的全部BBox能覆盖整个点云cube范围"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using matplotlib backend: Qt5Agg\n"
     ]
    }
   ],
   "source": [
    "%matplotlib auto\n",
    "anchors = anchor_generator.gen_anchors(flatten_output=True)\n",
    "w = VisualWindow(mode='3d')\n",
    "points = test_data['points']\n",
    "test_pc = points[points[:, 0] == 0][:, 1:]\n",
    "w.draw_point_cloud(pc=test_pc.cpu().numpy())\n",
    "sample_ids = torch.randperm(anchors.size(0))[:100]\n",
    "w.draw_boxes3d(boxes=anchors[sample_ids].cpu().numpy(), format='corner')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "anchor generator（二）\n",
    "- 在xyz坐标原点生成基本的anchors，然后通过stride。移动这些anchors"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "MultiClass Generator\n",
    "在同一feature map上为每种类别生成对应的anchor。输出\\[class_dim，xdim，ydim，zdim，size_dim,rot_dim,7\\]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "class_dim，xdim，ydim，zdim，size_dim,rot_dim,7: torch.Size([3, 176, 200, 1, 1, 2, 7])\n",
      "Car: tensor([[[[  0.2000, -39.8000,  -1.2000,   3.9000,   1.6000,   1.5600,   0.0000],\n",
      "          [  0.2000, -39.8000,  -1.2000,   3.9000,   1.6000,   1.5600,   1.5700]]]],\n",
      "       device='cuda:0')\n",
      "Pedestrian: tensor([[[[  0.2000, -39.8000,  -1.2000,   0.8000,   0.6000,   1.7300,   0.0000],\n",
      "          [  0.2000, -39.8000,  -1.2000,   0.8000,   0.6000,   1.7300,   1.5700]]]],\n",
      "       device='cuda:0')\n",
      "Cyclist tensor([[[[  0.2000, -39.8000,  -1.2000,   1.7600,   0.6000,   1.7300,   0.0000],\n",
      "          [  0.2000, -39.8000,  -1.2000,   1.7600,   0.6000,   1.7300,   1.5700]]]],\n",
      "       device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "from basic.module.dense_head.anchor_generator.anchor_gen_base import MultiClsAnchorGenerator\n",
    "\n",
    "mul_generator = MultiClsAnchorGenerator(anchor_gen_cfg, model_info_dict,\n",
    "                                        feature_map_size=output['spatial_features_2d'].shape[2:],\n",
    "                                        cls_list=['Car', 'Pedestrian', 'Cyclist'])\n",
    "all_anchors = mul_generator.gen_anchors(flatten_output=False)\n",
    "print(\"class_dim，xdim，ydim，zdim，size_dim,rot_dim,7:\", all_anchors.shape)\n",
    "print(\"Car:\", all_anchors[0, 0, 0])\n",
    "print(\"Pedestrian:\", all_anchors[1, 0, 0])\n",
    "print(\"Cyclist\", all_anchors[2, 0, 0])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Target assigner\n",
    "目的：1.训练时，为每个anchor指定类别标签和Boxes偏移量标签；\n",
    "输入：1.Anchors\\[K,7\\];2.Ground Truth Boxes\\[B,N,8\\],其中8=xyzhwlr+class_ind"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gt_box_temp: tensor([29.3264,  8.4339, -0.7402,  3.8006,  1.5304,  1.5709, -2.7242,  1.0000],\n",
      "       device='cuda:0')\n"
     ]
    },
    {
     "data": {
      "text/plain": "{'NAME': 'MaxIouTargetAssigner',\n 'DEVICE': 'cuda',\n 'POS_FRACTION': -1.0,\n 'NORM_BY_NUM_EXAMPLES': False,\n 'MATCH_HEIGHT': False,\n 'CLASS_THRESHOLD': [{'class_name': 'Car',\n   'pos_threshold': 0.5,\n   'neg_threshold': 0.45},\n  {'class_name': 'Pedestrian', 'pos_threshold': 0.5, 'neg_threshold': 0.35},\n  {'class_name': 'Cyclist', 'pos_threshold': 0.5, 'neg_threshold': 0.35}],\n 'IOU_CALCULATOR': {'NAME': 'Iou3DCalculator'},\n 'BOX_ENCODER': {'NAME': 'ResidualCoder',\n  'code_size': 7,\n  'encode_angle_by_sincos': False},\n 'SAMPLER': {'NAME': 'MaxSizeSubSampler', 'sample_size': 512}}"
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"gt_box_temp:\", test_data['gt_boxes'][0, 0])\n",
    "assigner_cfg = model_cfg.MODEL.DENSE_HEAD.TARGET_ASSIGNER_CONFIG\n",
    "assigner_cfg"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training True\n",
      "raw_point_feature_dims 4\n",
      "cur_point_feature_dims 512\n",
      "point_cloud_range [  0.  -40.   -3.   70.4  40.    1. ]\n",
      "voxel_size [0.05, 0.05, 0.1]\n",
      "grid_size [1408 1600   40]\n",
      "class_names ['Car']\n",
      "feature_map_size [  1 200 176]\n",
      "backbone_channels {'x_conv1': 16, 'x_conv2': 32, 'x_conv3': 64, 'x_conv4': 64}\n",
      "raw_anchor_shape [176, 200, 1, 1, 2]\n"
     ]
    }
   ],
   "source": [
    "for key, value in model_info_dict.items():\n",
    "    if key != 'module_list':\n",
    "        print(key, value)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "outputs": [],
   "source": [
    "from basic.module.dense_head.target_assigner import MaxIouTargetAssigner\n",
    "target_assigner = MaxIouTargetAssigner(assigner_cfg, model_info_dict)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "labels: tensor([[1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0.],\n",
      "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0.],\n",
      "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]],\n",
      "       device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ['CUDA_LAUNCH_BLOCKING'] = \"1\"\n",
    "print(\"labels:\", test_data['gt_boxes'][:, :, -1])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "outputs": [
    {
     "data": {
      "text/plain": "({'cls_labels': tensor([0., 0., 0.,  ..., 1., 1., 1.], device='cuda:0'),\n  'reg_labels': tensor([[0., 0., 0., 0., 0., 0., 0.],\n          [0., 0., 0., 0., 0., 0., 0.],\n          [0., 0., 0., 0., 0., 0., 0.],\n          [0., 0., 0., 0., 0., 0., 0.],\n          [0., 0., 0., 0., 0., 0., 0.],\n          [0., 0., 0., 0., 0., 0., 0.],\n          [0., 0., 0., 0., 0., 0., 0.],\n          [0., 0., 0., 0., 0., 0., 0.]], device='cuda:0')},\n {'pos': tensor([[    1,  3430],\n          [    1,  3830],\n          [    1, 24294],\n          [    2,  8965],\n          [    2,  8967],\n          [    3, 35437],\n          [    3, 35439],\n          [    3, 35837]], device='cuda:0'),\n  'neg': tensor([[    0,    13],\n          [    0,   226],\n          [    0,   297],\n          ...,\n          [    3, 69789],\n          [    3, 70059],\n          [    3, 70078]], device='cuda:0')})"
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# all_anchors = mul_generator.gen_anchors(flatten_output=True).cuda()\n",
    "all_anchors = anchor_generator.gen_anchors(flatten_output=True).to(device)\n",
    "target_dict, batch_bbox_id_dict = target_assigner.assign(gts=test_data['gt_boxes'][..., :-1], bboxes=all_anchors,\n",
    "                                                         gt_labels=test_data['gt_boxes'][..., -1])\n",
    "target_dict, batch_bbox_id_dict"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "可视化每个场景中，通过target assign匹配的anchor bbox"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using matplotlib backend: Qt5Agg\n",
      "tensor([ 3430,  3830, 24294], device='cuda:0')\n",
      "tensor([8965, 8967], device='cuda:0')\n",
      "tensor([35437, 35439, 35837], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "%matplotlib auto\n",
    "batch_bbox = batch_bbox_id_dict['pos']\n",
    "batch_ids = batch_bbox[:, 0]\n",
    "bbox_ids = batch_bbox[:, 1]\n",
    "points = test_data['points']\n",
    "for i in range(batch_size):\n",
    "    mask = batch_ids == i\n",
    "    frame_bbox_ids = bbox_ids[mask]\n",
    "    if frame_bbox_ids.size(0) > 0:\n",
    "        print(frame_bbox_ids)\n",
    "        frame_pc = points[points[:, 0] == i][:, 1:]\n",
    "        frame_bbox = all_anchors[frame_bbox_ids]\n",
    "        frame_gt = test_data['gt_boxes'][i]\n",
    "        w = VisualWindow(mode='3d')\n",
    "        w.draw_point_cloud(frame_pc.cpu().numpy())\n",
    "        w.draw_boxes3d(frame_gt[:,:7].cpu().numpy())\n",
    "        w.draw_boxes3d(frame_bbox.cpu().numpy(), 'corner', c='r')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "上面所有子模块组成基于anchor的Dense head：anchor head"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "outputs": [
    {
     "data": {
      "text/plain": "{'cls_pred': tensor([[-0.0898, -0.0097],\n         [-0.0898, -0.0097],\n         [-0.1206, -0.0532],\n         ...,\n         [ 0.1119, -0.0256],\n         [ 0.1119, -0.0256],\n         [ 0.0344, -0.0468]], device='cuda:0', grad_fn=<CatBackward>),\n 'reg_pred': tensor([[-0.1580, -0.0250,  0.0616, -0.0190, -0.0783,  0.0128,  0.0185],\n         [-0.1580, -0.0250,  0.0616, -0.0190, -0.0783,  0.0128,  0.0185],\n         [-0.0980,  0.0468, -0.0155, -0.0506, -0.0701, -0.0157,  0.0124],\n         [-0.1458, -0.0513, -0.0208,  0.0058, -0.0292, -0.0125,  0.1173],\n         [-0.1400, -0.0471, -0.0176,  0.0269, -0.0263, -0.0142,  0.1187],\n         [-0.0158, -0.0739, -0.0384,  0.0837,  0.1014, -0.0379,  0.1538],\n         [-0.0158, -0.0739, -0.0384,  0.0837,  0.1014, -0.0379,  0.1538],\n         [-0.0004,  0.0752,  0.0042, -0.0040,  0.0619, -0.0660,  0.1203]],\n        device='cuda:0', grad_fn=<IndexBackward>),\n 'target_dict': {'cls_labels': tensor([0., 0., 0.,  ..., 1., 1., 1.], device='cuda:0'),\n  'reg_labels': tensor([[0., 0., 0., 0., 0., 0., 0.],\n          [0., 0., 0., 0., 0., 0., 0.],\n          [0., 0., 0., 0., 0., 0., 0.],\n          [0., 0., 0., 0., 0., 0., 0.],\n          [0., 0., 0., 0., 0., 0., 0.],\n          [0., 0., 0., 0., 0., 0., 0.],\n          [0., 0., 0., 0., 0., 0., 0.],\n          [0., 0., 0., 0., 0., 0., 0.]], device='cuda:0')}}"
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from basic.module.dense_head.anchor_head.anchor_head_base import AnchorHeadBase\n",
    "\n",
    "dense_head_cfg = model_cfg.MODEL.DENSE_HEAD\n",
    "anchor_head = AnchorHeadBase(dense_head_cfg, model_info_dict).to(device)\n",
    "output_dict = anchor_head(output)\n",
    "output_dict"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "最后直接用模型配置文档生成SECOND模型"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "outputs": [],
   "source": [
    "from basic.model.second import SECOND\n",
    "\n",
    "data_infos = dataloader.dataset.get_data_infos()\n",
    "model = SECOND(model_cfg, data_infos).cuda()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "outputs": [
    {
     "data": {
      "text/plain": "{'loss': tensor(0.0647, device='cuda:0', grad_fn=<AddBackward0>)}"
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss = model(test_data)\n",
    "loss"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}