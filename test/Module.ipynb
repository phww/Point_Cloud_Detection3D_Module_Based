{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "import torch\n",
    "from kitti.kitti_dataset import get_dataloader\n",
    "import yaml\n",
    "from easydict import EasyDict\n",
    "from pathlib import Path\n",
    "from basic.utils.vis_utils import VisualWindow\n",
    "# %matplotlib inline\n",
    "torch.cuda.empty_cache()\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# DataLoader"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ph/Desktop/PointCloud/utils_my/kitti/kitti_dataset.py:30: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.\n",
      "  cfg = EasyDict(yaml.load(f))\n"
     ]
    }
   ],
   "source": [
    "cfg_path = Path(\"../kitti/cfg/kitti_dataset.yaml\")\n",
    "batch_size = 4\n",
    "dataloader = get_dataloader(data_cfg_path=cfg_path, class_name_list=['Car'], batch_size=batch_size)  # 'Pedestrian','Cyclist'"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input voxels shape: torch.Size([61791, 5, 4])\n"
     ]
    },
    {
     "data": {
      "text/plain": "{'frame_id': array(['006443', '007446', '005995', '006138'], dtype='<U6'),\n 'gt_boxes': tensor([[[26.9494, 11.7531, -0.7768,  3.6334,  1.6990,  1.6376,  0.3899,\n            1.0000],\n          [32.4706, 39.4742, -0.3389,  3.9609,  1.7706,  1.4636, -2.7501,\n            1.0000],\n          [35.3516, 19.9395, -0.4223,  3.9200,  1.6683,  1.6990,  1.4899,\n            1.0000],\n          [20.7630, 17.5684, -0.4604,  3.6027,  1.5045,  1.4841, -2.7301,\n            1.0000],\n          [11.6903, 15.1524, -1.0361,  4.1861,  1.6376,  1.3408, -2.6501,\n            1.0000],\n          [21.9628, 10.3106, -0.6254,  4.4829,  1.7092,  1.5557,  0.4199,\n            1.0000],\n          [32.8690,  8.3094, -0.4120,  4.2782,  1.9037,  1.5148, -1.2501,\n            1.0000],\n          [17.0427, 26.5958, -1.3451,  4.6057,  1.7092,  1.5148,  1.0499,\n            1.0000],\n          [16.4236,  3.2296, -0.6718,  4.2168,  1.8013,  1.7297, -1.2701,\n            1.0000],\n          [39.0840, 20.8829, -0.8285,  4.4215,  1.3612,  1.4124, -2.7401,\n            1.0000],\n          [23.5847, 40.7643, -0.6425,  3.7460,  1.6274,  1.5148, -2.0501,\n            1.0000],\n          [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n            0.0000],\n          [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n            0.0000]],\n \n         [[14.7800, 13.4765, -0.9279,  3.6418,  1.4928,  1.7686, -2.6407,\n            1.0000],\n          [20.2227, 16.5672, -0.8839,  4.2788,  1.6260,  1.4738, -2.6407,\n            1.0000],\n          [35.3171, 11.0457, -0.6012,  3.0903,  1.4073,  1.3597,  0.5593,\n            1.0000],\n          [26.0270, 32.1066, -1.0895,  3.1283,  1.5214,  1.5214,  1.8293,\n            1.0000],\n          [17.0866, 18.2033, -0.7698,  4.0982,  1.6260,  1.6640, -2.6907,\n            1.0000],\n          [21.0678, 37.1976, -0.9677,  3.3280,  1.3787,  1.3597, -0.9907,\n            1.0000],\n          [37.0599, 17.0035, -0.5993,  3.1568,  1.4168,  1.3122,  0.5093,\n            1.0000],\n          [18.9642, 10.0653, -0.5633,  4.1077,  1.6069,  1.6830,  0.4793,\n            1.0000],\n          [28.8656, 18.4261, -0.3869,  3.2139,  1.4548,  1.4263, -2.6507,\n            1.0000],\n          [19.6794,  7.9497, -0.6568,  3.5182,  1.5594,  1.3787,  0.4793,\n            1.0000],\n          [27.5457, 23.4559, -0.5067,  3.3375,  1.6830,  1.6069,  2.0393,\n            1.0000],\n          [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n            0.0000],\n          [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n            0.0000]],\n \n         [[16.9126, 12.8191, -0.8881,  3.2077,  1.6640,  1.6139,  0.6391,\n            1.0000],\n          [29.2295, 18.1079, -0.7714,  4.2302,  1.6640,  1.9146, -2.4940,\n            1.0000],\n          [27.5380,  7.1796, -0.6780,  4.2903,  1.5938,  1.4535, -2.4240,\n            1.0000],\n          [26.4141,  1.6760, -1.1265,  3.5084,  1.6239,  1.4234, -1.2140,\n            1.0000],\n          [21.0246, 10.6728, -1.0830,  4.0197,  1.5437,  1.5738, -2.5240,\n            1.0000],\n          [15.3770, 31.1859, -0.0602,  3.8493,  1.6039,  1.4836,  1.9891,\n            1.0000],\n          [12.8683, 20.1942, -0.5902,  3.2879,  1.5838,  1.5237, -1.6240,\n            1.0000],\n          [32.1689, 17.8417, -0.5723,  4.1299,  1.5938,  1.4635, -2.5140,\n            1.0000],\n          [52.2645, 12.1562, -0.3989,  3.3280,  1.5738,  1.5738,  0.6391,\n            1.0000],\n          [43.7081, 23.9663, -0.4641,  4.0197,  1.5938,  1.9347, -2.3640,\n            1.0000],\n          [ 6.4312, 18.3121, -0.4039,  3.5686,  1.6239,  1.7141, -1.6140,\n            1.0000],\n          [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n            0.0000],\n          [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n            0.0000]],\n \n         [[23.1587,  9.0031, -0.6946,  3.4924,  1.5511,  1.4655,  0.3708,\n            1.0000],\n          [30.7652, 11.3522, -0.5074,  4.1110,  1.6082,  1.6844,  0.3608,\n            1.0000],\n          [ 5.8242, -0.7111, -0.7504,  3.9302,  1.5416,  1.6558,  0.3308,\n            1.0000],\n          [13.0347,  1.8238, -0.7533,  3.1023,  1.3894,  1.4560,  0.3808,\n            1.0000],\n          [27.9382,  7.3417, -0.6122,  3.2831,  1.4845,  1.5226,  0.3608,\n            1.0000],\n          [33.0558,  9.5732, -0.5891,  3.8731,  1.4560,  1.4465,  0.4008,\n            1.0000],\n          [25.6550, 13.6717, -0.5590,  4.1110,  1.5797,  1.6368, -2.7692,\n            1.0000],\n          [34.2019, 32.4140, -0.6288,  4.1015,  1.5892,  1.3989, -2.8492,\n            1.0000],\n          [38.0130, 11.5306, -0.6134,  3.0737,  1.4940,  1.3418,  0.3908,\n            1.0000],\n          [49.4938, -4.0639, -1.7505,  4.0539,  1.3228,  1.5987,  2.0040,\n            1.0000],\n          [20.6138, -1.3555, -0.4462,  4.2157,  1.4465,  1.3989, -1.3492,\n            1.0000],\n          [37.6022, 20.8510, -0.7511,  3.5115,  1.5131,  1.4845, -2.9492,\n            1.0000],\n          [36.8137,  8.8872, -0.4757,  3.4734,  1.5321,  1.3228, -0.4592,\n            1.0000]]], device='cuda:0'),\n 'points': tensor([[ 0.0000, 25.7824, 21.1311,  0.1597,  0.3000],\n         [ 0.0000,  6.4301, -0.1964, -1.2548,  0.5900],\n         [ 0.0000, 18.3276,  4.8012,  0.6448,  0.1600],\n         ...,\n         [ 3.0000, 17.7890, 15.6565, -0.1370,  0.1100],\n         [ 3.0000,  5.5849,  3.3293, -1.5768,  0.1600],\n         [ 3.0000,  3.9902, -1.0058, -0.7994,  0.1800]], device='cuda:0'),\n 'use_lead_xyz': tensor([1., 1., 1., 1.], device='cuda:0'),\n 'voxels': tensor([[[25.7824, 21.1311,  0.1597,  0.3000],\n          [ 0.0000,  0.0000,  0.0000,  0.0000],\n          [ 0.0000,  0.0000,  0.0000,  0.0000],\n          [ 0.0000,  0.0000,  0.0000,  0.0000],\n          [ 0.0000,  0.0000,  0.0000,  0.0000]],\n \n         [[ 6.4301, -0.1964, -1.2548,  0.5900],\n          [ 0.0000,  0.0000,  0.0000,  0.0000],\n          [ 0.0000,  0.0000,  0.0000,  0.0000],\n          [ 0.0000,  0.0000,  0.0000,  0.0000],\n          [ 0.0000,  0.0000,  0.0000,  0.0000]],\n \n         [[18.3276,  4.8012,  0.6448,  0.1600],\n          [ 0.0000,  0.0000,  0.0000,  0.0000],\n          [ 0.0000,  0.0000,  0.0000,  0.0000],\n          [ 0.0000,  0.0000,  0.0000,  0.0000],\n          [ 0.0000,  0.0000,  0.0000,  0.0000]],\n \n         ...,\n \n         [[10.8141, 16.9435, -0.0866,  0.2300],\n          [ 0.0000,  0.0000,  0.0000,  0.0000],\n          [ 0.0000,  0.0000,  0.0000,  0.0000],\n          [ 0.0000,  0.0000,  0.0000,  0.0000],\n          [ 0.0000,  0.0000,  0.0000,  0.0000]],\n \n         [[17.7890, 15.6565, -0.1370,  0.1100],\n          [ 0.0000,  0.0000,  0.0000,  0.0000],\n          [ 0.0000,  0.0000,  0.0000,  0.0000],\n          [ 0.0000,  0.0000,  0.0000,  0.0000],\n          [ 0.0000,  0.0000,  0.0000,  0.0000]],\n \n         [[ 3.9902, -1.0058, -0.7994,  0.1800],\n          [ 0.0000,  0.0000,  0.0000,  0.0000],\n          [ 0.0000,  0.0000,  0.0000,  0.0000],\n          [ 0.0000,  0.0000,  0.0000,  0.0000],\n          [ 0.0000,  0.0000,  0.0000,  0.0000]]], device='cuda:0'),\n 'voxel_coords': tensor([[   0.,   31., 1222.,  515.],\n         [   0.,   17.,  796.,  128.],\n         [   0.,   36.,  896.,  366.],\n         ...,\n         [   3.,   29., 1138.,  216.],\n         [   3.,   28., 1113.,  355.],\n         [   3.,   22.,  779.,   79.]], device='cuda:0'),\n 'voxel_num_points': tensor([1., 1., 1.,  ..., 1., 1., 1.], device='cuda:0'),\n 'image_shape': tensor([[ 375, 1242,    3],\n         [ 375, 1242,    3],\n         [ 375, 1242,    3],\n         [ 375, 1242,    3]], device='cuda:0', dtype=torch.int32),\n 'batch_size': 4}"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from basic.utils.common_utils import put_data_to_gpu\n",
    "# 取一批数据用于模块测试\n",
    "for data in dataloader:\n",
    "    test_data = data\n",
    "    break\n",
    "# 单独把某些数据放在GPU中，注意frame_id这种还是为np.ndarray\n",
    "test_data = put_data_to_gpu(test_data)\n",
    "print(f\"input voxels shape:\", test_data['voxels'].shape)\n",
    "test_data"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Model cfg\n",
    "最终的目的是想用字符文档生成模型。但是下面只是单一测试每一个模块\n",
    "- model cfg 中包含各个模块的配置：module cfg\n",
    "- 在模型全局中使用model_info_dict记录一些必要的模型信息\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'DATASET_CONFIG': {'CONFIG_PATH': '/home/ph/Desktop/PointCloud/utils_my/kitti/cfg/kitti_dataset.yaml',\n",
      "                    'DATASET': 'KittiDataset',\n",
      "                    'DATA_AUGMENTOR': {'AUG_CONFIG_LIST': [{'DATABASE_WITH_FAKELIDAR': False,\n",
      "                                                            'DB_INFO_PATH': ['db_infos_train.pkl'],\n",
      "                                                            'LIMIT_WHOLE_SCENE': True,\n",
      "                                                            'NAME': 'gt_sampling',\n",
      "                                                            'NUM_POINT_FEATURES': 4,\n",
      "                                                            'PREPARE': {'filter_by_difficulty': [-1],\n",
      "                                                                        'filter_by_min_points': ['Car:5',\n",
      "                                                                                                 'Pedestrian:5',\n",
      "                                                                                                 'Cyclist:5']},\n",
      "                                                            'REMOVE_EXTRA_WIDTH': [0.0,\n",
      "                                                                                   0.0,\n",
      "                                                                                   0.0],\n",
      "                                                            'SAMPLE_GROUPS': ['Car:20',\n",
      "                                                                              'Pedestrian:15',\n",
      "                                                                              'Cyclist:15'],\n",
      "                                                            'USE_ROAD_PLANE': False},\n",
      "                                                           {'ALONG_AXIS_LIST': ['x'],\n",
      "                                                            'NAME': 'random_world_flip'},\n",
      "                                                           {'NAME': 'random_world_rotation',\n",
      "                                                            'WORLD_ROT_ANGLE': [-0.78539816,\n",
      "                                                                                0.78539816]},\n",
      "                                                           {'NAME': 'random_world_scaling',\n",
      "                                                            'WORLD_SCALE_RANGE': [0.95,\n",
      "                                                                                  1.05]}],\n",
      "                                       'DISABLE_AUG_LIST': ['placeholder'],\n",
      "                                       'RESERVED_FEATURE': ['frame_id',\n",
      "                                                            'points',\n",
      "                                                            'gt_boxes',\n",
      "                                                            'gt_names']},\n",
      "                    'DATA_PATH': '/home/ph/Dataset/KITTI',\n",
      "                    'DATA_PROCESSOR': [{'NAME': 'filter_points_and_boxes_inside_range',\n",
      "                                        'REMOVE_OUTSIDE_BOXES': True},\n",
      "                                       {'NAME': 'shuffle_points',\n",
      "                                        'SHUFFLE_ENABLED': {'test': False,\n",
      "                                                            'train': True}},\n",
      "                                       {'FULL_MEAN': False,\n",
      "                                        'MAX_NUMBER_OF_VOXELS': {'test': 40000,\n",
      "                                                                 'train': 16000},\n",
      "                                        'MAX_POINTS_PER_VOXEL': 5,\n",
      "                                        'NAME': 'transform_points_to_voxels',\n",
      "                                        'VOXEL_SIZE': [0.05, 0.05, 0.1]}],\n",
      "                    'DATA_SPLIT': {'test': 'val', 'train': 'train'},\n",
      "                    'FOV_POINTS_ONLY': True,\n",
      "                    'FOV_VIEW_POINTS': True,\n",
      "                    'GET_ITEM_LIST': ['points'],\n",
      "                    'INFO_PATH': {'test': ['infos_val.pkl'],\n",
      "                                  'train': ['infos_train.pkl']},\n",
      "                    'POINT_CLOUD_RANGE': [0, -40, -3, 70.4, 40, 1],\n",
      "                    'POINT_FEATURE_ENCODING': {'encoding_type': 'absolute_coordinates_encoding',\n",
      "                                               'src_feature_list': ['x',\n",
      "                                                                    'y',\n",
      "                                                                    'z',\n",
      "                                                                    'intensity'],\n",
      "                                               'used_feature_list': ['x',\n",
      "                                                                     'y',\n",
      "                                                                     'z',\n",
      "                                                                     'intensity']}},\n",
      " 'MODEL': {'BACKBONE2D': {'LAYER_NUMS': [5, 5],\n",
      "                          'LAYER_STRIDES': [1, 2],\n",
      "                          'NAME': 'BaseBEVBackbone',\n",
      "                          'NUM_FILTERS': [128, 256],\n",
      "                          'NUM_UPSAMPLE_FILTERS': [256, 256],\n",
      "                          'UPSAMPLE_STRIDES': [1, 2]},\n",
      "           'BACKBONE3D': {'DOWN_SAMPLE_RATE': 8, 'NAME': 'VoxelBackBone8x'},\n",
      "           'DENSE_HEAD': {'ANCHOR_GENERATOR_CONFIG': {'CLASS_CONFIG': [{'anchor_dims': 3,\n",
      "                                                                        'boxes_size': [[3.9,\n",
      "                                                                                        1.6,\n",
      "                                                                                        1.56]],\n",
      "                                                                        'center_aligned': True,\n",
      "                                                                        'class_name': 'Car',\n",
      "                                                                        'mode': 'Range',\n",
      "                                                                        'ratios': [1],\n",
      "                                                                        'road_plane_aligned': True,\n",
      "                                                                        'road_plane_height': -0.035,\n",
      "                                                                        'rotations': [0,\n",
      "                                                                                      1.57]},\n",
      "                                                                       {'anchor_dims': 3,\n",
      "                                                                        'boxes_size': [[0.8,\n",
      "                                                                                        0.6,\n",
      "                                                                                        1.73]],\n",
      "                                                                        'center_aligned': True,\n",
      "                                                                        'class_name': 'Pedestrian',\n",
      "                                                                        'mode': 'Range',\n",
      "                                                                        'ratios': [1],\n",
      "                                                                        'road_plane_aligned': True,\n",
      "                                                                        'road_plane_height': -1.2,\n",
      "                                                                        'rotations': [0,\n",
      "                                                                                      1.57]},\n",
      "                                                                       {'anchor_bottom_heights': [-0.6],\n",
      "                                                                        'anchor_dims': 3,\n",
      "                                                                        'boxes_size': [[1.76,\n",
      "                                                                                        0.6,\n",
      "                                                                                        1.73]],\n",
      "                                                                        'center_aligned': True,\n",
      "                                                                        'class_name': 'Cyclist',\n",
      "                                                                        'mode': 'Range',\n",
      "                                                                        'ratios': [1],\n",
      "                                                                        'road_plane_aligned': True,\n",
      "                                                                        'road_plane_height': -1.2,\n",
      "                                                                        'rotations': [0,\n",
      "                                                                                      1.57]}],\n",
      "                                                      'DEVICE': 'cuda',\n",
      "                                                      'NAME': 'AnchorGenerator'},\n",
      "                          'LOSS_CONFIG': {'CLS_LOSS': {'NAME': 'FocalLoss',\n",
      "                                                       'alpha': 0.75,\n",
      "                                                       'gamma': 3},\n",
      "                                          'LOSS_WEIGHTS': {'cls_weight': 1.0,\n",
      "                                                           'code_weights': [1.0,\n",
      "                                                                            1.0,\n",
      "                                                                            1.0,\n",
      "                                                                            1.0,\n",
      "                                                                            1.0,\n",
      "                                                                            1.0,\n",
      "                                                                            1.0],\n",
      "                                                           'dir_weight': 0.2,\n",
      "                                                           'reg_weight': 2.0},\n",
      "                                          'REG_LOSS': {'NAME': 'SmoothL1Loss',\n",
      "                                                       'beta': 0.5}},\n",
      "                          'NAME': 'AnchorHead',\n",
      "                          'TARGET_ASSIGNER_CONFIG': {'BOX_ENCODER': {'NAME': 'ResidualCoder',\n",
      "                                                                     'code_size': 7,\n",
      "                                                                     'encode_angle_by_sincos': False},\n",
      "                                                     'CLASS_THRESHOLD': [{'class_name': 'Car',\n",
      "                                                                          'neg_threshold': 0.4,\n",
      "                                                                          'pos_threshold': 0.55},\n",
      "                                                                         {'class_name': 'Pedestrian',\n",
      "                                                                          'neg_threshold': 0.35,\n",
      "                                                                          'pos_threshold': 0.5},\n",
      "                                                                         {'class_name': 'Cyclist',\n",
      "                                                                          'neg_threshold': 0.35,\n",
      "                                                                          'pos_threshold': 0.5}],\n",
      "                                                     'DEVICE': 'cuda',\n",
      "                                                     'FORCE_MATCH': True,\n",
      "                                                     'IOU_CALCULATOR': {'NAME': 'Iou3DCalculator'},\n",
      "                                                     'MATCH_HEIGHT': False,\n",
      "                                                     'NAME': 'MaxIouTargetAssigner',\n",
      "                                                     'NORM_BY_NUM_EXAMPLES': False,\n",
      "                                                     'POS_FRACTION': -1.0,\n",
      "                                                     'SAMPLER': {'NAME': 'MaxSizeSubSampler',\n",
      "                                                                 'sample_size': 128}}},\n",
      "           'FEATURE_EXTRACTOR': {'NAME': 'MeanVFE'},\n",
      "           'NAME': 'SECONDNet',\n",
      "           'NECK': {'DIM': 2,\n",
      "                    'NAME': 'DimCompression',\n",
      "                    'OUTPUT_FEATURE_DIMS': 256},\n",
      "           'POST_PROCESSING': {'EVAL_METRIC': 'kitti',\n",
      "                               'NMS_CONFIG': {'MULTI_CLASSES_NMS': False,\n",
      "                                              'NMS_POST_MAXSIZE': 500,\n",
      "                                              'NMS_PRE_MAXSIZE': 4096,\n",
      "                                              'NMS_THRESH': 0.01,\n",
      "                                              'NMS_TYPE': 'nms_gpu'},\n",
      "                               'OUTPUT_RAW_SCORE': False,\n",
      "                               'RECALL_THRESH_LIST': [0.3, 0.5, 0.7],\n",
      "                               'SCORE_THRESH': 0.1}},\n",
      " 'OPTIMIZATION': {'BATCH_SIZE_PER_GPU': 4,\n",
      "                  'DECAY_STEP_LIST': [35, 45],\n",
      "                  'DIV_FACTOR': 10,\n",
      "                  'GRAD_NORM_CLIP': 10,\n",
      "                  'LR': 0.003,\n",
      "                  'LR_CLIP': 1e-07,\n",
      "                  'LR_DECAY': 0.1,\n",
      "                  'LR_WARMUP': False,\n",
      "                  'MOMENTUM': 0.9,\n",
      "                  'MOMS': [0.95, 0.85],\n",
      "                  'NUM_EPOCHS': 80,\n",
      "                  'OPTIMIZER': 'adam_onecycle',\n",
      "                  'PCT_START': 0.4,\n",
      "                  'WARMUP_EPOCH': 1,\n",
      "                  'WEIGHT_DECAY': 0.01},\n",
      " 'PERPRO_CONFIG': {'CONFIG_PATH': '/home/ph/Desktop/PointCloud/utils_my/kitti/cfg/preprocess_cfg.yaml',\n",
      "                   'CREATE_GT_DATABASE': {'FLAG': True,\n",
      "                                          'USED_CLASSES': ['Car',\n",
      "                                                           'Pedestrian',\n",
      "                                                           'Cyclist']},\n",
      "                   'DATA_ROOT': '/home/ph/Dataset/KITTI',\n",
      "                   'DUMP_INTERVAL': 1000,\n",
      "                   'SAVE_ROOT': '/home/ph/Dataset/KITTI/infos',\n",
      "                   'WORKER_NUM': 4}}\n"
     ]
    }
   ],
   "source": [
    "from pprint import pprint\n",
    "from basic.utils.config_utils import cfg_from_yaml_file\n",
    "model_cfg = cfg_from_yaml_file('../basic/model/model_cfg/second.yaml')\n",
    "model_info_dict = {\n",
    "    'module_list': [],\n",
    "    'training': True,\n",
    "}\n",
    "data_infos = dataloader.dataset.get_data_infos()\n",
    "model_info_dict.update(data_infos)\n",
    "pprint(model_cfg)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "初始模型信息，注意经过每一个模块处理后,更新以下信息。\n",
    "- 更新module_list记录的模块\n",
    "- 当前特征图中每个点的特征维度\n",
    "- 后面模块可能会使用到的当前模块的一些信息"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "module_list:[]\n",
      "training:True\n",
      "raw_point_feature_dims:4\n",
      "cur_point_feature_dims:4\n",
      "point_cloud_range:[  0.  -40.   -3.   70.4  40.    1. ]\n",
      "voxel_size:[0.05, 0.05, 0.1]\n",
      "grid_size:[1408 1600   40]\n",
      "class_names:['Car']\n"
     ]
    }
   ],
   "source": [
    "for key, value in model_info_dict.items():\n",
    "    print(f\"{key}:{value}\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Feature Extractor/Encoding Module\n",
    "点云特征提取模块目的是：从无序的原始点云数据中提取出有序的初步特征,或者说找到一种方式编码原始点云，\n",
    "令其有序。其实就是把原始点云转换为有序的张量矩阵\n",
    "常见PointNet的方式，就是为了提取有序的初步特征；而体素的方式，是为了用体素这种格式编码原始点云，令其有序\n",
    "为什么要这样做？我的理解是，现有CNN只能处理有序的张量！！！不管是3d卷积还是2d卷积\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Voxel Feature Extractor(VFE)\n",
    "- 提取体素级别的特征\n",
    "输入：体素，以及体素相关的信息\n",
    "输出：提取的体素特征\n",
    "- Mean VFE：取每个体素内所有点的平均值作为输出特征\n",
    "- MLP VFE:对每个体素内的点集，做类似PointNet的操作。即用MLP + Max pooling 提取点集的特征"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean VFE： voxel_features shape: torch.Size([61791, 4])\n"
     ]
    }
   ],
   "source": [
    "#mean vfe\n",
    "from basic.module.feature_extractor import MeanVFE\n",
    "mean_vfe_module = MeanVFE(model_cfg, model_info_dict).cuda()\n",
    "output = mean_vfe_module(test_data)\n",
    "model_info_dict['cur_point_feature_dims'] = mean_vfe_module.output_feature_dims\n",
    "model_info_dict['module_list'].append(mean_vfe_module)\n",
    "print(f\"Mean VFE： voxel_features shape:\", output['voxel_features'].shape)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current model infos:\n",
      "module_list:[MeanVFE()]\n",
      "training:True\n",
      "raw_point_feature_dims:4\n",
      "cur_point_feature_dims:4\n",
      "point_cloud_range:[  0.  -40.   -3.   70.4  40.    1. ]\n",
      "voxel_size:[0.05, 0.05, 0.1]\n",
      "grid_size:[1408 1600   40]\n",
      "class_names:['Car']\n"
     ]
    }
   ],
   "source": [
    "print(f\"current model infos:\")\n",
    "for key, value in model_info_dict.items():\n",
    "    print(f\"{key}:{value}\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mlp VFE： voxel_features shape: torch.Size([61791, 128])\n"
     ]
    }
   ],
   "source": [
    "# mlp vfe just test\n",
    "from basic.module.feature_extractor import MlpVFE\n",
    "\n",
    "cfg = {'mlp_dims': [32, 64, 64, 128, 128],\n",
    "       'input_channels': 4}\n",
    "mlp_vfe_module = MlpVFE(cfg).cuda()\n",
    "t = mlp_vfe_module(test_data)\n",
    "print(f\"Mlp VFE： voxel_features shape:\", t.shape)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Point Feature Extractor(PFE)\n",
    "- 直接提取原始点云的特征\n",
    "- 代表方法PointNet++的SetAbstract layer"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "#todo"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Backbone3D\n",
    "- 经过原始点云的特征提取/编码后，一般会得到B,C,VH,VW,VD的体素张量特征矩阵。或B,C,H,W的点云特征张量矩阵。\n",
    "根据特征张量维度选择用3D卷积还是2D卷积网络来进一步提取特征。\n",
    "- 因为体素张量特征矩阵非常稀疏，多使用稀疏卷积。使用spconv库来进行稀疏3D卷积"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "spconv_tensor_shape: torch.Size([4, 128, 2, 200, 176])\n"
     ]
    }
   ],
   "source": [
    "from basic.module.backbone3d import VoxelBackBone8x\n",
    "\n",
    "back3d_cfg = model_cfg.MODEL.BACKBONE3D\n",
    "backbone3d_module = VoxelBackBone8x(back3d_cfg, model_info_dict).cuda()\n",
    "output = backbone3d_module(output)\n",
    "print(f\"spconv_tensor_shape:\", output['encoded_spconv_tensor'].dense().shape)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "model_info_dict['module_list'].append(backbone3d_module)\n",
    "model_info_dict['cur_point_feature_dims'] = backbone3d_module.output_feature_dims\n",
    "model_info_dict['feature_map_size'] = backbone3d_module.output_feature_size\n",
    "model_info_dict['backbone_channels'] = backbone3d_module.backbone_channels\\\n",
    "    if hasattr(backbone3d_module, 'backbone_channels') else None"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current model infos:\n",
      "module_list:[MeanVFE(), VoxelBackBone8x(\n",
      "  (conv_input): SparseSequential(\n",
      "    (0): SubMConv3d()\n",
      "    (1): BatchNorm1d(16, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "    (2): ReLU()\n",
      "  )\n",
      "  (conv1): SparseSequential(\n",
      "    (0): SparseSequential(\n",
      "      (0): SubMConv3d()\n",
      "      (1): BatchNorm1d(16, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "      (2): ReLU()\n",
      "    )\n",
      "  )\n",
      "  (conv2): SparseSequential(\n",
      "    (0): SparseSequential(\n",
      "      (0): SparseConv3d()\n",
      "      (1): BatchNorm1d(32, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "      (2): ReLU()\n",
      "    )\n",
      "    (1): SparseSequential(\n",
      "      (0): SubMConv3d()\n",
      "      (1): BatchNorm1d(32, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "      (2): ReLU()\n",
      "    )\n",
      "    (2): SparseSequential(\n",
      "      (0): SubMConv3d()\n",
      "      (1): BatchNorm1d(32, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "      (2): ReLU()\n",
      "    )\n",
      "  )\n",
      "  (conv3): SparseSequential(\n",
      "    (0): SparseSequential(\n",
      "      (0): SparseConv3d()\n",
      "      (1): BatchNorm1d(64, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "      (2): ReLU()\n",
      "    )\n",
      "    (1): SparseSequential(\n",
      "      (0): SubMConv3d()\n",
      "      (1): BatchNorm1d(64, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "      (2): ReLU()\n",
      "    )\n",
      "    (2): SparseSequential(\n",
      "      (0): SubMConv3d()\n",
      "      (1): BatchNorm1d(64, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "      (2): ReLU()\n",
      "    )\n",
      "  )\n",
      "  (conv4): SparseSequential(\n",
      "    (0): SparseSequential(\n",
      "      (0): SparseConv3d()\n",
      "      (1): BatchNorm1d(64, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "      (2): ReLU()\n",
      "    )\n",
      "    (1): SparseSequential(\n",
      "      (0): SubMConv3d()\n",
      "      (1): BatchNorm1d(64, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "      (2): ReLU()\n",
      "    )\n",
      "    (2): SparseSequential(\n",
      "      (0): SubMConv3d()\n",
      "      (1): BatchNorm1d(64, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "      (2): ReLU()\n",
      "    )\n",
      "  )\n",
      "  (conv_out): SparseSequential(\n",
      "    (0): SparseConv3d()\n",
      "    (1): BatchNorm1d(128, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "    (2): ReLU()\n",
      "  )\n",
      ")]\n",
      "training:True\n",
      "raw_point_feature_dims:4\n",
      "cur_point_feature_dims:128\n",
      "point_cloud_range:[  0.  -40.   -3.   70.4  40.    1. ]\n",
      "voxel_size:[0.05, 0.05, 0.1]\n",
      "grid_size:[1408 1600   40]\n",
      "class_names:['Car']\n",
      "feature_map_size:[  2 200 176]\n",
      "backbone_channels:{'x_conv1': 16, 'x_conv2': 32, 'x_conv3': 64, 'x_conv4': 64}\n"
     ]
    }
   ],
   "source": [
    "print(f\"current model infos:\")\n",
    "for key, value in model_info_dict.items():\n",
    "    print(f\"{key}:{value}\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# NECK\n",
    "BackBone3D提取的特征向量依然处于3维空间内。目前一般不会在3维空间内提取ROIs。因为3DNMS，3DIOU等都很麻烦....。\n",
    "因此直接在前视图FOV或在鸟瞰图BEV上提取ROIs。为此需要将3d特征转换为2d特征。\n",
    "- 常用的Neck：\n",
    "直接压缩：比如将B,C,D,H,W的特征压缩为B，C*H，D,W,此时的特征图可以认为是BEV视角下的二维特征图"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "直接压缩 torch.Size([4, 256, 200, 176])\n"
     ]
    }
   ],
   "source": [
    "from basic.module.neck import DimCompression\n",
    "\n",
    "neck_cfg = model_cfg.MODEL.NECK\n",
    "neck_module = DimCompression(module_cfg=neck_cfg, model_info_dict=model_info_dict)\n",
    "output = neck_module(output)\n",
    "print(\"直接压缩\", output['spatial_features'].shape)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [
    "model_info_dict['module_list'].append(neck_module)\n",
    "model_info_dict['cur_point_feature_dims'] = neck_module.output_feature_dims\n",
    "model_info_dict['feature_map_size'] = neck_module.output_feature_size"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current model infos:\n",
      "module_list:[MeanVFE(), VoxelBackBone8x(\n",
      "  (conv_input): SparseSequential(\n",
      "    (0): SubMConv3d()\n",
      "    (1): BatchNorm1d(16, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "    (2): ReLU()\n",
      "  )\n",
      "  (conv1): SparseSequential(\n",
      "    (0): SparseSequential(\n",
      "      (0): SubMConv3d()\n",
      "      (1): BatchNorm1d(16, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "      (2): ReLU()\n",
      "    )\n",
      "  )\n",
      "  (conv2): SparseSequential(\n",
      "    (0): SparseSequential(\n",
      "      (0): SparseConv3d()\n",
      "      (1): BatchNorm1d(32, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "      (2): ReLU()\n",
      "    )\n",
      "    (1): SparseSequential(\n",
      "      (0): SubMConv3d()\n",
      "      (1): BatchNorm1d(32, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "      (2): ReLU()\n",
      "    )\n",
      "    (2): SparseSequential(\n",
      "      (0): SubMConv3d()\n",
      "      (1): BatchNorm1d(32, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "      (2): ReLU()\n",
      "    )\n",
      "  )\n",
      "  (conv3): SparseSequential(\n",
      "    (0): SparseSequential(\n",
      "      (0): SparseConv3d()\n",
      "      (1): BatchNorm1d(64, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "      (2): ReLU()\n",
      "    )\n",
      "    (1): SparseSequential(\n",
      "      (0): SubMConv3d()\n",
      "      (1): BatchNorm1d(64, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "      (2): ReLU()\n",
      "    )\n",
      "    (2): SparseSequential(\n",
      "      (0): SubMConv3d()\n",
      "      (1): BatchNorm1d(64, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "      (2): ReLU()\n",
      "    )\n",
      "  )\n",
      "  (conv4): SparseSequential(\n",
      "    (0): SparseSequential(\n",
      "      (0): SparseConv3d()\n",
      "      (1): BatchNorm1d(64, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "      (2): ReLU()\n",
      "    )\n",
      "    (1): SparseSequential(\n",
      "      (0): SubMConv3d()\n",
      "      (1): BatchNorm1d(64, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "      (2): ReLU()\n",
      "    )\n",
      "    (2): SparseSequential(\n",
      "      (0): SubMConv3d()\n",
      "      (1): BatchNorm1d(64, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "      (2): ReLU()\n",
      "    )\n",
      "  )\n",
      "  (conv_out): SparseSequential(\n",
      "    (0): SparseConv3d()\n",
      "    (1): BatchNorm1d(128, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "    (2): ReLU()\n",
      "  )\n",
      "), DimCompression()]\n",
      "training:True\n",
      "raw_point_feature_dims:4\n",
      "cur_point_feature_dims:256\n",
      "point_cloud_range:[  0.  -40.   -3.   70.4  40.    1. ]\n",
      "voxel_size:[0.05, 0.05, 0.1]\n",
      "grid_size:[1408 1600   40]\n",
      "class_names:['Car']\n",
      "feature_map_size:[  1 200 176]\n",
      "backbone_channels:{'x_conv1': 16, 'x_conv2': 32, 'x_conv3': 64, 'x_conv4': 64}\n"
     ]
    }
   ],
   "source": [
    "print(f\"current model infos:\")\n",
    "for key, value in model_info_dict.items():\n",
    "    print(f\"{key}:{value}\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Backbone2D\n",
    "与BackBone3D一样，根据输入的张量维度。选择用2D卷积网络提取特征。通常如果使用NECK 模块将3维空间内的特征压缩为2维空间的特征后\n",
    "也会再次使用2D的卷积网络再次提取特征。"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [],
   "source": [
    "# from basic.module.backbone2d import BEVExtractor\n",
    "# conv_channels = [32, 64, 128, 256]\n",
    "# conv_kernel = [2, 2, 3, 3]\n",
    "# backbone2d = BEVExtractor(128, conv_channels, conv_kernel)\n",
    "# output = backbone2d(output)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "data": {
      "text/plain": "torch.Size([4, 512, 200, 176])"
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from basic.module.backbone2d.base_bev_backbone import BaseBEVBackbone\n",
    "\n",
    "backbone2d_cfg = model_cfg.MODEL.BACKBONE2D\n",
    "backbone2d = BaseBEVBackbone(backbone2d_cfg, model_info_dict).cuda()\n",
    "output = backbone2d(output)\n",
    "output['spatial_features_2d'].shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [],
   "source": [
    "model_info_dict['module_list'].append(backbone2d)\n",
    "model_info_dict['cur_point_feature_dims'] = backbone2d.output_feature_dims"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current model infos:\n",
      "module_list:[MeanVFE(), VoxelBackBone8x(\n",
      "  (conv_input): SparseSequential(\n",
      "    (0): SubMConv3d()\n",
      "    (1): BatchNorm1d(16, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "    (2): ReLU()\n",
      "  )\n",
      "  (conv1): SparseSequential(\n",
      "    (0): SparseSequential(\n",
      "      (0): SubMConv3d()\n",
      "      (1): BatchNorm1d(16, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "      (2): ReLU()\n",
      "    )\n",
      "  )\n",
      "  (conv2): SparseSequential(\n",
      "    (0): SparseSequential(\n",
      "      (0): SparseConv3d()\n",
      "      (1): BatchNorm1d(32, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "      (2): ReLU()\n",
      "    )\n",
      "    (1): SparseSequential(\n",
      "      (0): SubMConv3d()\n",
      "      (1): BatchNorm1d(32, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "      (2): ReLU()\n",
      "    )\n",
      "    (2): SparseSequential(\n",
      "      (0): SubMConv3d()\n",
      "      (1): BatchNorm1d(32, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "      (2): ReLU()\n",
      "    )\n",
      "  )\n",
      "  (conv3): SparseSequential(\n",
      "    (0): SparseSequential(\n",
      "      (0): SparseConv3d()\n",
      "      (1): BatchNorm1d(64, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "      (2): ReLU()\n",
      "    )\n",
      "    (1): SparseSequential(\n",
      "      (0): SubMConv3d()\n",
      "      (1): BatchNorm1d(64, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "      (2): ReLU()\n",
      "    )\n",
      "    (2): SparseSequential(\n",
      "      (0): SubMConv3d()\n",
      "      (1): BatchNorm1d(64, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "      (2): ReLU()\n",
      "    )\n",
      "  )\n",
      "  (conv4): SparseSequential(\n",
      "    (0): SparseSequential(\n",
      "      (0): SparseConv3d()\n",
      "      (1): BatchNorm1d(64, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "      (2): ReLU()\n",
      "    )\n",
      "    (1): SparseSequential(\n",
      "      (0): SubMConv3d()\n",
      "      (1): BatchNorm1d(64, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "      (2): ReLU()\n",
      "    )\n",
      "    (2): SparseSequential(\n",
      "      (0): SubMConv3d()\n",
      "      (1): BatchNorm1d(64, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "      (2): ReLU()\n",
      "    )\n",
      "  )\n",
      "  (conv_out): SparseSequential(\n",
      "    (0): SparseConv3d()\n",
      "    (1): BatchNorm1d(128, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "    (2): ReLU()\n",
      "  )\n",
      "), DimCompression(), BaseBEVBackbone(\n",
      "  (blocks): ModuleList(\n",
      "    (0): Sequential(\n",
      "      (0): ZeroPad2d(padding=(1, 1, 1, 1), value=0.0)\n",
      "      (1): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
      "      (2): BatchNorm2d(128, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "      (3): ReLU()\n",
      "      (4): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (5): BatchNorm2d(128, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "      (6): ReLU()\n",
      "      (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (8): BatchNorm2d(128, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "      (9): ReLU()\n",
      "      (10): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (11): BatchNorm2d(128, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "      (12): ReLU()\n",
      "      (13): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (14): BatchNorm2d(128, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "      (15): ReLU()\n",
      "      (16): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (17): BatchNorm2d(128, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "      (18): ReLU()\n",
      "    )\n",
      "    (1): Sequential(\n",
      "      (0): ZeroPad2d(padding=(1, 1, 1, 1), value=0.0)\n",
      "      (1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
      "      (2): BatchNorm2d(256, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "      (3): ReLU()\n",
      "      (4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (5): BatchNorm2d(256, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "      (6): ReLU()\n",
      "      (7): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (8): BatchNorm2d(256, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "      (9): ReLU()\n",
      "      (10): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (11): BatchNorm2d(256, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "      (12): ReLU()\n",
      "      (13): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (14): BatchNorm2d(256, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "      (15): ReLU()\n",
      "      (16): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (17): BatchNorm2d(256, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "      (18): ReLU()\n",
      "    )\n",
      "  )\n",
      "  (deblocks): ModuleList(\n",
      "    (0): Sequential(\n",
      "      (0): ConvTranspose2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (1): BatchNorm2d(256, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "      (2): ReLU()\n",
      "    )\n",
      "    (1): Sequential(\n",
      "      (0): ConvTranspose2d(256, 256, kernel_size=(2, 2), stride=(2, 2), bias=False)\n",
      "      (1): BatchNorm2d(256, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "      (2): ReLU()\n",
      "    )\n",
      "  )\n",
      ")]\n",
      "training:True\n",
      "raw_point_feature_dims:4\n",
      "cur_point_feature_dims:512\n",
      "point_cloud_range:[  0.  -40.   -3.   70.4  40.    1. ]\n",
      "voxel_size:[0.05, 0.05, 0.1]\n",
      "grid_size:[1408 1600   40]\n",
      "class_names:['Car']\n",
      "feature_map_size:[  1 200 176]\n",
      "backbone_channels:{'x_conv1': 16, 'x_conv2': 32, 'x_conv3': 64, 'x_conv4': 64}\n"
     ]
    }
   ],
   "source": [
    "print(f\"current model infos:\")\n",
    "for key, value in model_info_dict.items():\n",
    "    print(f\"{key}:{value}\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "截止目前为止：输入点云的shape变化为\n",
    "- 原始点云->体素：183149, 5, 4\n",
    "- VFE：183149, 4\n",
    "- BackBone3D：12， 128， 2， 200， 176\n",
    "- neck：12，256，200，176\n",
    "- BackBone2D：12，256，200，176，shape未变因为卷积过后，又转置卷积回了原始大小\n",
    "经过上面的各个模块，从原始点云中获取了能代表该点云的二维特征图。接下来是3D目标识别中最重要的部分：Dense Head 与 ROI head。"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Dense Head\n",
    "BackBone2D的输出为用于Bbox回归的，和Bbox分类的两个likelihood矩阵"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "anchor generator（一）\n",
    "- 枚举7种anchor可能用到的特征，即x，y，z，h，w，l，r。然后通过mesh gird产生所有anchors。其中根据anchor中心坐标xyz的取法不同又分为Range和Stride两种方案\n",
    "    - Range：在点云范围内，给定每个轴的取值范围。每个轴按照特征图中对应的维度平均划分这些轴。比如特征图对应X轴的维度大小为176，就在X轴范围内平均划分176个。\n",
    "    - Stride：给定xyz坐标下的原点坐标，分别以x stride，y stride，z stride沿着各个轴的正方向按步长获得anchor中心坐标xyz。\n",
    "    - 代码接口虽然可以自定义Range和Stride。但是为了将特征图上的每个特征点与原图上的每个anchor关联起来，一定要平均划分！！即Range取值为点云的范围，而Stride取值为\n",
    "  点云采样范围 / 特征图大小。即\\[z_stride, x_stride, y_stride\\]=\\[z_len, x_len, y_len\\] / \\[H, W, L\\]。这样看按Range还是Stride的方案取得的结果应该差距不大。。。\n",
    "    - 实际上就是把特征图上的每个特征点，映射回了原始数据上对应区域的中心？假如原始点云下采样了8倍得到特征图，则特征图中\\[0,0,0\\]点对应原点云（点云原点坐标为000）中以\\[8,8,8\\]为中心，边长为8的正方形区域？"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [
    {
     "data": {
      "text/plain": "({'NAME': 'AnchorGenerator',\n  'DEVICE': 'cuda',\n  'CLASS_CONFIG': [{'class_name': 'Car',\n    'mode': 'Range',\n    'anchor_dims': 3,\n    'boxes_size': [[3.9, 1.6, 1.56]],\n    'rotations': [0, 1.57],\n    'ratios': [1],\n    'center_aligned': True,\n    'road_plane_aligned': True,\n    'road_plane_height': -0.035},\n   {'class_name': 'Pedestrian',\n    'mode': 'Range',\n    'anchor_dims': 3,\n    'boxes_size': [[0.8, 0.6, 1.73]],\n    'rotations': [0, 1.57],\n    'ratios': [1],\n    'center_aligned': True,\n    'road_plane_aligned': True,\n    'road_plane_height': -1.2},\n   {'class_name': 'Cyclist',\n    'mode': 'Range',\n    'anchor_dims': 3,\n    'boxes_size': [[1.76, 0.6, 1.73]],\n    'rotations': [0, 1.57],\n    'ratios': [1],\n    'center_aligned': True,\n    'anchor_bottom_heights': [-0.6],\n    'road_plane_aligned': True,\n    'road_plane_height': -1.2}]},\n {'module_list': [MeanVFE(),\n   VoxelBackBone8x(\n     (conv_input): SparseSequential(\n       (0): SubMConv3d()\n       (1): BatchNorm1d(16, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n       (2): ReLU()\n     )\n     (conv1): SparseSequential(\n       (0): SparseSequential(\n         (0): SubMConv3d()\n         (1): BatchNorm1d(16, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n         (2): ReLU()\n       )\n     )\n     (conv2): SparseSequential(\n       (0): SparseSequential(\n         (0): SparseConv3d()\n         (1): BatchNorm1d(32, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n         (2): ReLU()\n       )\n       (1): SparseSequential(\n         (0): SubMConv3d()\n         (1): BatchNorm1d(32, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n         (2): ReLU()\n       )\n       (2): SparseSequential(\n         (0): SubMConv3d()\n         (1): BatchNorm1d(32, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n         (2): ReLU()\n       )\n     )\n     (conv3): SparseSequential(\n       (0): SparseSequential(\n         (0): SparseConv3d()\n         (1): BatchNorm1d(64, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n         (2): ReLU()\n       )\n       (1): SparseSequential(\n         (0): SubMConv3d()\n         (1): BatchNorm1d(64, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n         (2): ReLU()\n       )\n       (2): SparseSequential(\n         (0): SubMConv3d()\n         (1): BatchNorm1d(64, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n         (2): ReLU()\n       )\n     )\n     (conv4): SparseSequential(\n       (0): SparseSequential(\n         (0): SparseConv3d()\n         (1): BatchNorm1d(64, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n         (2): ReLU()\n       )\n       (1): SparseSequential(\n         (0): SubMConv3d()\n         (1): BatchNorm1d(64, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n         (2): ReLU()\n       )\n       (2): SparseSequential(\n         (0): SubMConv3d()\n         (1): BatchNorm1d(64, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n         (2): ReLU()\n       )\n     )\n     (conv_out): SparseSequential(\n       (0): SparseConv3d()\n       (1): BatchNorm1d(128, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n       (2): ReLU()\n     )\n   ),\n   DimCompression(),\n   BaseBEVBackbone(\n     (blocks): ModuleList(\n       (0): Sequential(\n         (0): ZeroPad2d(padding=(1, 1, 1, 1), value=0.0)\n         (1): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), bias=False)\n         (2): BatchNorm2d(128, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n         (3): ReLU()\n         (4): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n         (5): BatchNorm2d(128, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n         (6): ReLU()\n         (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n         (8): BatchNorm2d(128, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n         (9): ReLU()\n         (10): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n         (11): BatchNorm2d(128, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n         (12): ReLU()\n         (13): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n         (14): BatchNorm2d(128, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n         (15): ReLU()\n         (16): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n         (17): BatchNorm2d(128, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n         (18): ReLU()\n       )\n       (1): Sequential(\n         (0): ZeroPad2d(padding=(1, 1, 1, 1), value=0.0)\n         (1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), bias=False)\n         (2): BatchNorm2d(256, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n         (3): ReLU()\n         (4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n         (5): BatchNorm2d(256, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n         (6): ReLU()\n         (7): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n         (8): BatchNorm2d(256, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n         (9): ReLU()\n         (10): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n         (11): BatchNorm2d(256, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n         (12): ReLU()\n         (13): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n         (14): BatchNorm2d(256, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n         (15): ReLU()\n         (16): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n         (17): BatchNorm2d(256, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n         (18): ReLU()\n       )\n     )\n     (deblocks): ModuleList(\n       (0): Sequential(\n         (0): ConvTranspose2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n         (1): BatchNorm2d(256, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n         (2): ReLU()\n       )\n       (1): Sequential(\n         (0): ConvTranspose2d(256, 256, kernel_size=(2, 2), stride=(2, 2), bias=False)\n         (1): BatchNorm2d(256, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n         (2): ReLU()\n       )\n     )\n   )],\n  'training': True,\n  'raw_point_feature_dims': 4,\n  'cur_point_feature_dims': 512,\n  'point_cloud_range': array([  0. , -40. ,  -3. ,  70.4,  40. ,   1. ], dtype=float32),\n  'voxel_size': [0.05, 0.05, 0.1],\n  'grid_size': array([1408, 1600,   40]),\n  'class_names': ['Car'],\n  'feature_map_size': array([  1, 200, 176]),\n  'backbone_channels': {'x_conv1': 16,\n   'x_conv2': 32,\n   'x_conv3': 64,\n   'x_conv4': 64}})"
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# anchor generator config\n",
    "anchor_gen_cfg = model_cfg.MODEL.DENSE_HEAD.ANCHOR_GENERATOR_CONFIG\n",
    "anchor_gen_cfg, model_info_dict"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Range anchors shape: torch.Size([176, 200, 1, 1, 2, 7])\n",
      "Range stride: tensor([[[[0.4000, 0.4000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [0.4000, 0.4000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]]],\n",
      "       device='cuda:0')\n",
      "begin: tensor([[[[ 2.0000e-01, -3.9800e+01, -3.5000e-02,  3.9000e+00,  1.6000e+00,\n",
      "            1.5600e+00,  0.0000e+00],\n",
      "          [ 2.0000e-01, -3.9800e+01, -3.5000e-02,  3.9000e+00,  1.6000e+00,\n",
      "            1.5600e+00,  1.5700e+00]]]], device='cuda:0')\n",
      "end: tensor([[[[ 7.0200e+01,  3.9800e+01, -3.5000e-02,  3.9000e+00,  1.6000e+00,\n",
      "            1.5600e+00,  0.0000e+00],\n",
      "          [ 7.0200e+01,  3.9800e+01, -3.5000e-02,  3.9000e+00,  1.6000e+00,\n",
      "            1.5600e+00,  1.5700e+00]]]], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "from basic.module.dense_head.anchor_generator.anchor_gen_base import AnchorGenerator\n",
    "\n",
    "anchor_generator = AnchorGenerator(anchor_gen_cfg, model_info_dict, class_type='Car', dtype=torch.float32)\n",
    "anchors = anchor_generator.gen_anchors(flatten_output=False)\n",
    "print(\"Range anchors shape:\", anchors.shape)\n",
    "print(\"Range stride:\", anchors[1, 1] - anchors[0, 0])\n",
    "print(\"begin:\", anchors[0, 0])\n",
    "print(\"end:\", anchors[-1, -1])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([ 33.8000, -35.0000,  -0.0350,   3.9000,   1.6000,   1.5600,   0.0000],\n       device='cuda:0')"
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "anchors[84,12,0,0,0]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "stride: tensor([0.4000, 0.4000, 4.0000])\n",
      "Stride anchors shape: torch.Size([176, 200, 1, 1, 2, 7])\n",
      "begin: tensor([[[[ 2.0000e-01, -3.9800e+01, -3.5000e-02,  3.9000e+00,  1.6000e+00,\n",
      "            1.5600e+00,  0.0000e+00],\n",
      "          [ 2.0000e-01, -3.9800e+01, -3.5000e-02,  3.9000e+00,  1.6000e+00,\n",
      "            1.5600e+00,  1.5700e+00]]]], device='cuda:0')\n",
      "end: tensor([[[[ 7.0200e+01,  3.9800e+01, -3.5000e-02,  3.9000e+00,  1.6000e+00,\n",
      "            1.5600e+00,  0.0000e+00],\n",
      "          [ 7.0200e+01,  3.9800e+01, -3.5000e-02,  3.9000e+00,  1.6000e+00,\n",
      "            1.5600e+00,  1.5700e+00]]]], device='cuda:0')\n",
      "output anchor shape: torch.Size([70400, 7])\n"
     ]
    }
   ],
   "source": [
    "anchor_generator.set_mode('Stride')\n",
    "anchors = anchor_generator.gen_anchors(flatten_output=False)\n",
    "print(\"stride:\", anchor_generator.stride)\n",
    "print(\"Stride anchors shape:\", anchors.shape)\n",
    "print(\"begin:\", anchors[0, 0])\n",
    "print(\"end:\", anchors[-1, -1])\n",
    "final_anchors = anchors.view(-1, 7)\n",
    "print(\"output anchor shape:\", final_anchors.shape)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "1.注意输出anchors的shape为176, 200, 1, 1, 2, 7。最后一个维度代表anchor的特征向量xyzlwhr，\n",
    "其他维度分别与x y z size rot的可枚举数量一致.当然最后输出的shape为(176x200x1x1x2, 7)\n",
    "2.在对齐体素中心的情况下，Range和Stride两种方案的结果都是一样的。假如点云的x轴范围为\\[0, 70.4\\]，\n",
    "而x轴对应的维度在特征图上大小为176.则均分后相邻点的距离为70.4 / 176 = 0.4。Range和Stride\n",
    "枚举X坐标的核心代码如下"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [],
   "source": [
    "ranges = torch.linspace(0, 70.4, 176)\n",
    "range_align_center = torch.linspace(0 + 0.2, 70.4 - 0.2, 176)\n",
    "stride = torch.arange(0, 176) * 0.4\n",
    "stride_align_center = stride + 0.4 / 2"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [],
   "source": [
    "anchor_generator.set_mode('Range')\n",
    "model_info_dict['raw_anchor_shape'] = anchor_generator.shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "随机绘制100个anchor box看看\n",
    "- 明显anchor 产生的全部BBox能覆盖整个点云cube范围"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using matplotlib backend: Qt5Agg\n"
     ]
    }
   ],
   "source": [
    "%matplotlib auto\n",
    "anchors = anchor_generator.gen_anchors(flatten_output=True)\n",
    "w = VisualWindow(mode='3d')\n",
    "points = test_data['points']\n",
    "test_pc = points[points[:, 0] == 0][:, 1:]\n",
    "w.draw_point_cloud(pc=test_pc.cpu().numpy())\n",
    "sample_ids = torch.randperm(anchors.size(0))[:100]\n",
    "w.draw_boxes3d(boxes=anchors[sample_ids].cpu().numpy(), format='corner')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "anchor generator（二）\n",
    "- 在xyz坐标原点生成基本的anchors，然后通过stride。移动这些anchors"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "MultiClass Generator\n",
    "在同一feature map上为每种类别生成对应的anchor。输出\\[class_dim，xdim，ydim，zdim，size_dim,rot_dim,7\\]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "class_dim，xdim，ydim，zdim，size_dim,rot_dim,7: torch.Size([3, 176, 200, 1, 1, 2, 7])\n",
      "Car: tensor([[[[ 2.0000e-01, -3.9800e+01, -3.5000e-02,  3.9000e+00,  1.6000e+00,\n",
      "            1.5600e+00,  0.0000e+00],\n",
      "          [ 2.0000e-01, -3.9800e+01, -3.5000e-02,  3.9000e+00,  1.6000e+00,\n",
      "            1.5600e+00,  1.5700e+00]]]], device='cuda:0')\n",
      "Pedestrian: tensor([[[[  0.2000, -39.8000,  -1.2000,   0.8000,   0.6000,   1.7300,   0.0000],\n",
      "          [  0.2000, -39.8000,  -1.2000,   0.8000,   0.6000,   1.7300,   1.5700]]]],\n",
      "       device='cuda:0')\n",
      "Cyclist tensor([[[[  0.2000, -39.8000,  -1.2000,   1.7600,   0.6000,   1.7300,   0.0000],\n",
      "          [  0.2000, -39.8000,  -1.2000,   1.7600,   0.6000,   1.7300,   1.5700]]]],\n",
      "       device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "from basic.module.dense_head.anchor_generator.anchor_gen_base import MultiClsAnchorGenerator\n",
    "\n",
    "mul_generator = MultiClsAnchorGenerator(anchor_gen_cfg, model_info_dict,\n",
    "                                        feature_map_size=output['spatial_features_2d'].shape[2:],\n",
    "                                        cls_list=['Car', 'Pedestrian', 'Cyclist'])\n",
    "all_anchors = mul_generator.gen_anchors(flatten_output=False)\n",
    "print(\"class_dim，xdim，ydim，zdim，size_dim,rot_dim,7:\", all_anchors.shape)\n",
    "print(\"Car:\", all_anchors[0, 0, 0])\n",
    "print(\"Pedestrian:\", all_anchors[1, 0, 0])\n",
    "print(\"Cyclist\", all_anchors[2, 0, 0])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Target assigner\n",
    "目的：1.训练时，为每个anchor指定类别标签和Boxes偏移量标签；\n",
    "输入：1.Anchors\\[K,7\\];2.Ground Truth Boxes\\[B,N,8\\],其中8=xyzhwlr+class_ind"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gt_box_temp: tensor([26.9494, 11.7531, -0.7768,  3.6334,  1.6990,  1.6376,  0.3899,  1.0000],\n",
      "       device='cuda:0')\n"
     ]
    },
    {
     "data": {
      "text/plain": "{'NAME': 'MaxIouTargetAssigner',\n 'DEVICE': 'cuda',\n 'FORCE_MATCH': True,\n 'POS_FRACTION': -1.0,\n 'NORM_BY_NUM_EXAMPLES': False,\n 'MATCH_HEIGHT': False,\n 'CLASS_THRESHOLD': [{'class_name': 'Car',\n   'pos_threshold': 0.55,\n   'neg_threshold': 0.4},\n  {'class_name': 'Pedestrian', 'pos_threshold': 0.5, 'neg_threshold': 0.35},\n  {'class_name': 'Cyclist', 'pos_threshold': 0.5, 'neg_threshold': 0.35}],\n 'IOU_CALCULATOR': {'NAME': 'Iou3DCalculator'},\n 'BOX_ENCODER': {'NAME': 'ResidualCoder',\n  'code_size': 7,\n  'encode_angle_by_sincos': False},\n 'SAMPLER': {'NAME': 'MaxSizeSubSampler', 'sample_size': 128}}"
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"gt_box_temp:\", test_data['gt_boxes'][0, 0])\n",
    "assigner_cfg = model_cfg.MODEL.DENSE_HEAD.TARGET_ASSIGNER_CONFIG\n",
    "assigner_cfg"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training True\n",
      "raw_point_feature_dims 4\n",
      "cur_point_feature_dims 512\n",
      "point_cloud_range [  0.  -40.   -3.   70.4  40.    1. ]\n",
      "voxel_size [0.05, 0.05, 0.1]\n",
      "grid_size [1408 1600   40]\n",
      "class_names ['Car']\n",
      "feature_map_size [  1 200 176]\n",
      "backbone_channels {'x_conv1': 16, 'x_conv2': 32, 'x_conv3': 64, 'x_conv4': 64}\n",
      "raw_anchor_shape [176, 200, 1, 1, 2]\n"
     ]
    }
   ],
   "source": [
    "for key, value in model_info_dict.items():\n",
    "    if key != 'module_list':\n",
    "        print(key, value)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "outputs": [],
   "source": [
    "from basic.module.dense_head.target_assigner import MaxIouTargetAssigner\n",
    "target_assigner = MaxIouTargetAssigner(assigner_cfg, model_info_dict)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "labels: tensor([[1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0.],\n",
      "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0.],\n",
      "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0.],\n",
      "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ['CUDA_LAUNCH_BLOCKING'] = \"1\"\n",
    "print(\"labels:\", test_data['gt_boxes'][:, :, -1])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "outputs": [],
   "source": [
    "# all_anchors = mul_generator.gen_anchors(flatten_output=True).cuda()\n",
    "all_anchors = anchor_generator.gen_anchors(flatten_output=True).to(device)\n",
    "target_assigner.force_match = True\n",
    "# target_dict, batch_bbox_id_dict = target_assigner.assign(gts=test_data['gt_boxes'][..., :-1], bboxes=all_anchors, gt_labels=test_data['gt_boxes'][:, :, -1])\n",
    "assign_ret = target_assigner.assign(gts=test_data['gt_boxes'][..., :-1], bboxes=all_anchors, gt_labels=test_data['gt_boxes'][..., -1])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[    0,     4, 11874],\n        [    0,     8, 16615],\n        [    0,     7, 17133],\n        [    0,     3, 20686],\n        [    0,     5, 21850],\n        [    0,    10, 23599],\n        [    0,     0, 27058],\n        [    0,     1, 32796],\n        [    0,     6, 33041],\n        [    0,     2, 35499],\n        [    0,     9, 39104],\n        [    1,     0, 14666],\n        [    1,     4, 17090],\n        [    1,     7, 19050],\n        [    1,     9, 19838],\n        [    1,     1, 20282],\n        [    1,     5, 21185],\n        [    1,     3, 26361],\n        [    1,    10, 27517],\n        [    1,     8, 29092],\n        [    1,     2, 35454],\n        [    1,     6, 37084],\n        [    2,    10,  6691],\n        [    2,     6, 13101],\n        [    2,     5, 15555],\n        [    2,     5, 15557],\n        [    2,     0, 17064],\n        [    2,     4, 21052],\n        [    2,     3, 26609],\n        [    2,     2, 27434],\n        [    2,     1, 29490],\n        [    2,     7, 32288],\n        [    2,     9, 43518],\n        [    2,     8, 52260],\n        [    3,     9,     0],\n        [    3,     2,  5796],\n        [    3,     3, 13008],\n        [    3,    10, 20593],\n        [    3,     0, 23044],\n        [    3,     6, 25868],\n        [    3,     4, 27836],\n        [    3,     1, 30656],\n        [    3,     5, 33046],\n        [    3,     7, 34362],\n        [    3,    12, 37044],\n        [    3,    11, 37904],\n        [    3,     8, 38256]], device='cuda:0')"
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pos_tuples = assign_ret.pos_tuples\n",
    "neg_tuples = assign_ret.neg_tuples\n",
    "pos_tuples"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3],\n",
      "       device='cuda:0')\n",
      "tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True],\n",
      "       device='cuda:0')\n",
      "tensor([11874, 16615, 17133, 20686, 21850, 23599, 27058, 32796, 33041, 35499,\n",
      "        39104, 14666, 17090, 19050, 19838, 20282, 21185, 26361, 27517, 29092,\n",
      "        35454, 37084,  6691, 13101, 15555, 15557, 17064, 21052, 26609, 27434,\n",
      "        29490, 32288, 43518, 52260,     0,  5796, 13008, 20593, 23044, 25868,\n",
      "        27836, 30656, 33046, 34362, 37044, 37904, 38256], device='cuda:0')\n",
      "tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True],\n",
      "       device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "t1, t2 = torch.where(assign_ret.pos_tuples_dense >= 0)\n",
    "print(t1)\n",
    "print(t1 == pos_tuples[:, 0])\n",
    "print(t2)\n",
    "print(t2 == pos_tuples[:, 2])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[    0, 11874],\n",
      "        [    0, 16615],\n",
      "        [    0, 17133],\n",
      "        [    0, 20686],\n",
      "        [    0, 21850],\n",
      "        [    0, 23599],\n",
      "        [    0, 27058],\n",
      "        [    0, 32796],\n",
      "        [    0, 33041],\n",
      "        [    0, 35499],\n",
      "        [    0, 39104],\n",
      "        [    1, 14666],\n",
      "        [    1, 17090],\n",
      "        [    1, 19050],\n",
      "        [    1, 19838],\n",
      "        [    1, 20282],\n",
      "        [    1, 21185],\n",
      "        [    1, 26361],\n",
      "        [    1, 27517],\n",
      "        [    1, 29092],\n",
      "        [    1, 35454],\n",
      "        [    1, 37084],\n",
      "        [    2,  6691],\n",
      "        [    2, 13101],\n",
      "        [    2, 15555],\n",
      "        [    2, 15557],\n",
      "        [    2, 17064],\n",
      "        [    2, 21052],\n",
      "        [    2, 26609],\n",
      "        [    2, 27434],\n",
      "        [    2, 29490],\n",
      "        [    2, 32288],\n",
      "        [    2, 43518],\n",
      "        [    2, 52260],\n",
      "        [    3,     0],\n",
      "        [    3,  5796],\n",
      "        [    3, 13008],\n",
      "        [    3, 20593],\n",
      "        [    3, 23044],\n",
      "        [    3, 25868],\n",
      "        [    3, 27836],\n",
      "        [    3, 30656],\n",
      "        [    3, 33046],\n",
      "        [    3, 34362],\n",
      "        [    3, 37044],\n",
      "        [    3, 37904],\n",
      "        [    3, 38256]], device='cuda:0')\n",
      "tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True],\n",
      "       device='cuda:0')\n",
      "tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True],\n",
      "       device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "t = assign_ret.bbox_targets.nonzero()[:, :2].unique(dim=0)\n",
    "print(t)\n",
    "print(t[:,0] == pos_tuples[:, 0])\n",
    "print(t[:,1] == pos_tuples[:, 2])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([11874, 16615, 17133, 20686, 21850, 23599, 27058, 32796, 33041, 35499,\n",
      "        39104, 14666, 17090, 19050, 19838, 20282, 21185, 26361, 27517, 29092,\n",
      "        35454, 37084,  6691, 13101, 15555, 15557, 17064, 21052, 26609, 27434,\n",
      "        29490, 32288, 43518, 52260,     0,  5796, 13008, 20593, 23044, 25868,\n",
      "        27836, 30656, 33046, 34362, 37044, 37904, 38256], device='cuda:0')\n",
      "tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True],\n",
      "       device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "t = torch.where(assign_ret.bbox_weights == 1)[1]\n",
    "print(t)\n",
    "print(t == pos_tuples[:, -1])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([    0,   389,   509,   678,   984,  1390,  1413,  1468,  1572,  1591,\n",
      "         1630,  1761,  1784,  1941,  1994,  2431,  2556,  2596,  2697,  2808,\n",
      "         2915,  3011,  3209,  3729,  3730,  4041,  4083,  4091,  4188,  4199,\n",
      "         4395,  4465,  4472,  4541,  4894,  5003,  5116,  5191,  5326,  5382,\n",
      "         5400,  5567,  5598,  5796,  6135,  6303,  6641,  6691,  6703,  7027,\n",
      "         7049,  7373,  7977,  8062,  8069,  8177,  8277,  8389,  8426,  8438,\n",
      "         8537,  8632,  8831,  8947,  9067,  9106,  9200,  9321,  9337,  9482,\n",
      "         9636,  9735,  9787, 10596, 10702, 10818, 11035, 11054, 11055, 11117,\n",
      "        11181, 11199, 11213, 11241, 11270, 11409, 11827, 11874, 11897, 12141,\n",
      "        12405, 12577, 13008, 13101, 13306, 13368, 13376, 13422, 13541, 13592,\n",
      "        13703, 13785, 13808, 13921, 14106, 14225, 14652, 14666, 14764, 14821,\n",
      "        14848, 15065, 15083, 15537, 15555, 15557, 15795, 15886, 15988, 16064,\n",
      "        16097, 16176, 16521, 16591, 16615, 17026, 17064, 17090, 17131, 17133,\n",
      "        17192, 17283, 17541, 17600, 17704, 17748, 17894, 18044, 18070, 18287,\n",
      "        18440, 18584, 18594, 18708, 18736, 18754, 18968, 19050, 19280, 19334,\n",
      "        19367, 19653, 19681, 19838, 19908, 20096, 20282, 20303, 20328, 20435,\n",
      "        20495, 20593, 20686, 20755, 20894, 21021, 21038, 21052, 21146, 21185,\n",
      "        21850, 21909, 21922, 21981, 22146, 22202, 22666, 22693, 22717, 22842,\n",
      "        23044, 23357, 23395, 23583, 23599, 23616, 23634, 23767, 23903, 23982,\n",
      "        24428, 24674, 24713, 24747, 24752, 25073, 25192, 25314, 25595, 25665,\n",
      "        25782, 25868, 25892, 25962, 26029, 26071, 26284, 26361, 26394, 26609,\n",
      "        26859, 26898, 26945, 26951, 26972, 27058, 27074, 27142, 27215, 27434,\n",
      "        27517, 27716, 27836, 28429, 28490, 28526, 28737, 28870, 29092, 29146,\n",
      "        29184, 29290, 29338, 29413, 29437, 29462, 29490, 29950, 30049, 30256,\n",
      "        30339, 30511, 30656, 30712, 31089, 31178, 31210, 31697, 31796, 31933,\n",
      "        31946, 32005, 32027, 32288, 32401, 32486, 32705, 32796, 32965, 33022,\n",
      "        33041, 33046, 33144, 33173, 33502, 33902, 34243, 34362, 34635, 34697,\n",
      "        34774, 34812, 34966, 35021, 35078, 35261, 35274, 35421, 35454, 35499,\n",
      "        35746, 35875, 35965, 35986, 36004, 36178, 36418, 36437, 36532, 36724,\n",
      "        36918, 37044, 37084, 37163, 37403, 37452, 37593, 37627, 37901, 37904,\n",
      "        38089, 38129, 38256, 38669, 38896, 38968, 39104, 39149, 39624, 39759,\n",
      "        39833, 39881, 40079, 40091, 40163, 40251, 40267, 40276, 40499, 40597,\n",
      "        40655, 40967, 41024, 41403, 41556, 42010, 42024, 42137, 42233, 42346,\n",
      "        42420, 42848, 42945, 43235, 43364, 43397, 43518, 43590, 43715, 43882,\n",
      "        43890, 43913, 44162, 44162, 44189, 44367, 44642, 44842, 45097, 45224,\n",
      "        45236, 45336, 45358, 45408, 45416, 45450, 46131, 46181, 46246, 46260,\n",
      "        46427, 46741, 46968, 47163, 47445, 47586, 47598, 47608, 47783, 47938,\n",
      "        48382, 48440, 48515, 48542, 48680, 48747, 48841, 48903, 49104, 49108,\n",
      "        49264, 49362, 49624, 50025, 50122, 50376, 50381, 50386, 50426, 50610,\n",
      "        50769, 50885, 50966, 51629, 51739, 51897, 51924, 51950, 52116, 52148,\n",
      "        52260, 52342, 52369, 52390, 52474, 52621, 52640, 52766, 52792, 52857,\n",
      "        52951, 53339, 53428, 53567, 53640, 53698, 53812, 53845, 54150, 54287,\n",
      "        54338, 54624, 54674, 54723, 54802, 55229, 55272, 55447, 55711, 55976,\n",
      "        56019, 56023, 56133, 56191, 56218, 56230, 56245, 56790, 57157, 57159,\n",
      "        57222, 57310, 57450, 57951, 57969, 58355, 58929, 59024, 59161, 59523,\n",
      "        59649, 59810, 59968, 60012, 60186, 60225, 60434, 60959, 61108, 61209,\n",
      "        61265, 61538, 61960, 62035, 62354, 62544, 62550, 62554, 62846, 63028,\n",
      "        63065, 63097, 63140, 63300, 64062, 64137, 64204, 64233, 64369, 64417,\n",
      "        64682, 64883, 64968, 65067, 65210, 65403, 65457, 65858, 66078, 66156,\n",
      "        66277, 66503, 66643, 66740, 66779, 66932, 66962, 67019, 67666, 67921,\n",
      "        68068, 68176, 68301, 68348, 68357, 68613, 68898, 68954, 69176, 69862,\n",
      "        70072, 70153], device='cuda:0')\n"
     ]
    },
    {
     "data": {
      "text/plain": "tensor([    0,   389,   509,   678,   984,  1390,  1413,  1468,  1572,  1591,\n         1630,  1761,  1784,  1941,  1994,  2431,  2556,  2596,  2697,  2808,\n         2915,  3011,  3209,  3729,  3730,  4041,  4083,  4091,  4188,  4199,\n         4395,  4465,  4472,  4541,  4894,  5003,  5116,  5191,  5326,  5382,\n         5400,  5567,  5598,  5796,  6135,  6303,  6641,  6691,  6703,  7027,\n         7049,  7373,  7977,  8062,  8069,  8177,  8277,  8389,  8426,  8438,\n         8537,  8632,  8831,  8947,  9067,  9106,  9200,  9321,  9337,  9482,\n         9636,  9735,  9787, 10596, 10702, 10818, 11035, 11054, 11055, 11117,\n        11181, 11199, 11213, 11241, 11270, 11409, 11827, 11874, 11897, 12141,\n        12405, 12577, 13008, 13101, 13306, 13368, 13376, 13422, 13541, 13592,\n        13703, 13785, 13808, 13921, 14106, 14225, 14652, 14666, 14764, 14821,\n        14848, 15065, 15083, 15537, 15555, 15557, 15795, 15886, 15988, 16064,\n        16097, 16176, 16521, 16591, 16615, 17026, 17064, 17090, 17131, 17133,\n        17192, 17283, 17541, 17600, 17704, 17748, 17894, 18044, 18070, 18287,\n        18440, 18584, 18594, 18708, 18736, 18754, 18968, 19050, 19280, 19334,\n        19367, 19653, 19681, 19838, 19908, 20096, 20282, 20303, 20328, 20435,\n        20495, 20593, 20686, 20755, 20894, 21021, 21038, 21052, 21146, 21185,\n        21850, 21909, 21922, 21981, 22146, 22202, 22666, 22693, 22717, 22842,\n        23044, 23357, 23395, 23583, 23599, 23616, 23634, 23767, 23903, 23982,\n        24428, 24674, 24713, 24747, 24752, 25073, 25192, 25314, 25595, 25665,\n        25782, 25868, 25892, 25962, 26029, 26071, 26284, 26361, 26394, 26609,\n        26859, 26898, 26945, 26951, 26972, 27058, 27074, 27142, 27215, 27434,\n        27517, 27716, 27836, 28429, 28490, 28526, 28737, 28870, 29092, 29146,\n        29184, 29290, 29338, 29413, 29437, 29462, 29490, 29950, 30049, 30256,\n        30339, 30511, 30656, 30712, 31089, 31178, 31210, 31697, 31796, 31933,\n        31946, 32005, 32027, 32288, 32401, 32486, 32705, 32796, 32965, 33022,\n        33041, 33046, 33144, 33173, 33502, 33902, 34243, 34362, 34635, 34697,\n        34774, 34812, 34966, 35021, 35078, 35261, 35274, 35421, 35454, 35499,\n        35746, 35875, 35965, 35986, 36004, 36178, 36418, 36437, 36532, 36724,\n        36918, 37044, 37084, 37163, 37403, 37452, 37593, 37627, 37901, 37904,\n        38089, 38129, 38256, 38669, 38896, 38968, 39104, 39149, 39624, 39759,\n        39833, 39881, 40079, 40091, 40163, 40251, 40267, 40276, 40499, 40597,\n        40655, 40967, 41024, 41403, 41556, 42010, 42024, 42137, 42233, 42346,\n        42420, 42848, 42945, 43235, 43364, 43397, 43518, 43590, 43715, 43882,\n        43890, 43913, 44162, 44162, 44189, 44367, 44642, 44842, 45097, 45224,\n        45236, 45336, 45358, 45408, 45416, 45450, 46131, 46181, 46246, 46260,\n        46427, 46741, 46968, 47163, 47445, 47586, 47598, 47608, 47783, 47938,\n        48382, 48440, 48515, 48542, 48680, 48747, 48841, 48903, 49104, 49108,\n        49264, 49362, 49624, 50025, 50122, 50376, 50381, 50386, 50426, 50610,\n        50769, 50885, 50966, 51629, 51739, 51897, 51924, 51950, 52116, 52148,\n        52260, 52342, 52369, 52390, 52474, 52621, 52640, 52766, 52792, 52857,\n        52951, 53339, 53428, 53567, 53640, 53698, 53812, 53845, 54150, 54287,\n        54338, 54624, 54674, 54723, 54802, 55229, 55272, 55447, 55711, 55976,\n        56019, 56023, 56133, 56191, 56218, 56230, 56245, 56790, 57157, 57159,\n        57222, 57310, 57450, 57951, 57969, 58355, 58929, 59024, 59161, 59523,\n        59649, 59810, 59968, 60012, 60186, 60225, 60434, 60959, 61108, 61209,\n        61265, 61538, 61960, 62035, 62354, 62544, 62550, 62554, 62846, 63028,\n        63065, 63097, 63140, 63300, 64062, 64137, 64204, 64233, 64369, 64417,\n        64682, 64883, 64968, 65067, 65210, 65403, 65457, 65858, 66078, 66156,\n        66277, 66503, 66643, 66740, 66779, 66932, 66962, 67019, 67666, 67921,\n        68068, 68176, 68301, 68348, 68357, 68613, 68898, 68954, 69176, 69862,\n        70072, 70153], device='cuda:0')"
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = torch.where(assign_ret.cls_weights == 1)\n",
    "print(t[1].sort()[0])\n",
    "torch.cat([ pos_tuples[:, -1], neg_tuples[: ,-1]]).sort()[0]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "可视化每个场景中，通过target assign匹配的anchor bbox"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using matplotlib backend: Qt5Agg\n",
      "tensor([11874, 16615, 17133, 20686, 21850, 23599, 27058, 32796, 33041, 35499,\n",
      "        39104], device='cuda:0')\n",
      "tensor([14666, 17090, 19050, 19838, 20282, 21185, 26361, 27517, 29092, 35454,\n",
      "        37084], device='cuda:0')\n",
      "tensor([ 6691, 13101, 15555, 15557, 17064, 21052, 26609, 27434, 29490, 32288,\n",
      "        43518, 52260], device='cuda:0')\n",
      "tensor([    0,  5796, 13008, 20593, 23044, 25868, 27836, 30656, 33046, 34362,\n",
      "        37044, 37904, 38256], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "%matplotlib auto\n",
    "batch_bbox = assign_ret.pos_tuples\n",
    "batch_ids = batch_bbox[:, 0]\n",
    "bbox_ids = batch_bbox[:, 2]\n",
    "points = test_data['points']\n",
    "for i in range(batch_size):\n",
    "    mask = batch_ids == i\n",
    "    frame_bbox_ids = bbox_ids[mask]\n",
    "    if frame_bbox_ids.size(0) > 0:\n",
    "        print(frame_bbox_ids)\n",
    "        frame_pc = points[points[:, 0] == i][:, 1:]\n",
    "        frame_bbox = all_anchors[frame_bbox_ids]\n",
    "        frame_gt = test_data['gt_boxes'][i]\n",
    "        w = VisualWindow(mode='3d')\n",
    "        w.draw_point_cloud(frame_pc.cpu().numpy())\n",
    "        w.draw_boxes3d(frame_gt[:,:7].cpu().numpy())\n",
    "        w.draw_boxes3d(frame_bbox.cpu().numpy(), 'corner', c='r')\n",
    "        # break"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "上面所有子模块组成基于anchor的Dense head：anchor head"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "outputs": [
    {
     "data": {
      "text/plain": "{'cls_pred': tensor([[[ 0.0535,  0.0362],\n          [-0.0991,  0.0921],\n          [-0.1281,  0.0632],\n          ...,\n          [ 0.0034,  0.1971],\n          [ 0.0562,  0.0372],\n          [-0.0977,  0.0159]],\n \n         [[ 0.0535,  0.0362],\n          [-0.0991,  0.0921],\n          [-0.1281,  0.0632],\n          ...,\n          [-0.0010,  0.1844],\n          [ 0.0756,  0.0342],\n          [-0.0740,  0.0276]],\n \n         [[ 0.0535,  0.0362],\n          [-0.0991,  0.0921],\n          [-0.1281,  0.0632],\n          ...,\n          [-0.0376,  0.0809],\n          [ 0.0240,  0.0535],\n          [-0.0754, -0.0015]],\n \n         [[ 0.0535,  0.0362],\n          [-0.0991,  0.0921],\n          [-0.1281,  0.0632],\n          ...,\n          [-0.0186,  0.1782],\n          [ 0.0634,  0.0500],\n          [-0.0739,  0.0267]]], device='cuda:0', grad_fn=<UnsafeViewBackward>),\n 'reg_pred': tensor([[[ 1.0238e-01,  3.4355e-02, -4.8905e-02,  ..., -1.3527e-01,\n            4.9688e-02,  1.3377e-01],\n          [-8.4775e-02,  2.8270e-02, -6.8721e-02,  ...,  1.0473e-01,\n           -5.8037e-03,  4.1153e-02],\n          [-6.1151e-02,  5.0426e-03, -2.7364e-05,  ..., -8.6259e-02,\n            4.7720e-02,  6.7198e-02],\n          ...,\n          [-1.8988e-02,  1.3773e-02,  5.6039e-02,  ...,  4.6249e-02,\n            1.5960e-01,  1.6095e-02],\n          [-6.5945e-02,  1.8743e-02, -4.5069e-02,  ..., -9.8937e-02,\n            2.8479e-02,  1.0031e-01],\n          [ 1.2927e-01,  6.0437e-02, -7.3381e-02,  ...,  7.1002e-02,\n            4.6932e-02, -1.8019e-02]],\n \n         [[ 1.0238e-01,  3.4355e-02, -4.8905e-02,  ..., -1.3527e-01,\n            4.9688e-02,  1.3377e-01],\n          [-8.4775e-02,  2.8270e-02, -6.8721e-02,  ...,  1.0473e-01,\n           -5.8037e-03,  4.1153e-02],\n          [-6.1151e-02,  5.0426e-03, -2.7364e-05,  ..., -8.6259e-02,\n            4.7720e-02,  6.7198e-02],\n          ...,\n          [-1.1638e-02, -2.0822e-02,  2.8313e-02,  ...,  5.7169e-02,\n            1.5913e-01,  1.4982e-02],\n          [-8.7793e-02,  2.5982e-02, -5.0698e-02,  ..., -7.0596e-02,\n            3.5600e-02,  9.7254e-02],\n          [ 1.3023e-01,  6.0223e-02, -6.5815e-02,  ...,  5.6965e-02,\n            5.4042e-02, -3.7248e-02]],\n \n         [[ 1.0238e-01,  3.4355e-02, -4.8905e-02,  ..., -1.3527e-01,\n            4.9688e-02,  1.3377e-01],\n          [-8.4775e-02,  2.8270e-02, -6.8721e-02,  ...,  1.0473e-01,\n           -5.8037e-03,  4.1153e-02],\n          [-6.1151e-02,  5.0426e-03, -2.7364e-05,  ..., -8.6259e-02,\n            4.7720e-02,  6.7198e-02],\n          ...,\n          [-3.5116e-02,  5.4553e-02, -5.7407e-03,  ..., -4.3604e-02,\n            6.9247e-02, -3.8172e-02],\n          [-1.1386e-01,  1.1191e-01, -9.5204e-02,  ..., -8.6725e-02,\n           -3.9621e-02,  1.0687e-01],\n          [ 9.0192e-02,  9.6576e-02, -4.3053e-02,  ..., -4.7778e-02,\n           -7.5352e-02,  1.3777e-02]],\n \n         [[ 1.0238e-01,  3.4355e-02, -4.8905e-02,  ..., -1.3527e-01,\n            4.9688e-02,  1.3377e-01],\n          [-8.4775e-02,  2.8270e-02, -6.8721e-02,  ...,  1.0473e-01,\n           -5.8037e-03,  4.1153e-02],\n          [-6.1151e-02,  5.0426e-03, -2.7364e-05,  ..., -8.6259e-02,\n            4.7720e-02,  6.7198e-02],\n          ...,\n          [-2.2740e-02, -7.0144e-03,  4.1448e-02,  ...,  5.5547e-02,\n            1.4606e-01,  1.2562e-02],\n          [-9.1939e-02,  3.7308e-02, -5.2789e-02,  ..., -8.2317e-02,\n            4.6983e-02,  9.4022e-02],\n          [ 1.1939e-01,  6.9317e-02, -5.7510e-02,  ...,  7.9269e-02,\n            4.7560e-02, -4.5822e-02]]], device='cuda:0',\n        grad_fn=<UnsafeViewBackward>),\n 'assign_result': <basic.datatype.assign_result.AssignResult at 0x7f7f5310eb80>}"
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from basic.module.dense_head.anchor_head.anchor_head_base import AnchorHeadBase\n",
    "dense_head_cfg = model_cfg.MODEL.DENSE_HEAD\n",
    "anchor_head = AnchorHeadBase(dense_head_cfg, model_info_dict).to(device)\n",
    "output_dict = anchor_head(output)\n",
    "output_dict"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "最后直接用模型配置文档生成SECOND模型"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "outputs": [],
   "source": [
    "from basic.model.second import SECOND\n",
    "\n",
    "data_infos = dataloader.dataset.get_data_infos()\n",
    "model = SECOND(model_cfg, data_infos).cuda()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor(2.3224, device='cuda:0', grad_fn=<AddBackward0>)"
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss = model(test_data)\n",
    "loss['tol_loss']"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "IOU"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "outputs": [],
   "source": [
    "s = torch.randn(10, 1000, 4)\n",
    "max_s,arg_s = s.max(dim=-1)\n",
    "_,topk = max_s.topk(5, dim=1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[634, 136, 114, 423, 921],\n        [822, 211, 518, 544, 639],\n        [940, 481,   2, 476, 608],\n        [605,  37,  92, 988, 412],\n        [437, 205, 757, 176, 792],\n        [605, 749, 573, 216,  56],\n        [498, 470,   6, 981, 912],\n        [780, 987, 165, 895, 208],\n        [ 17, 416, 333, 111, 455],\n        [171, 298,   4, 931, 157]])"
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topk"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "outputs": [
    {
     "data": {
      "text/plain": "(tensor([0, 0, 0,  ..., 9, 9, 9]),\n tensor([  0,   2,   4,  ..., 997, 998, 999]))"
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.where(arg_s > 0)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "outputs": [
    {
     "data": {
      "text/plain": "True"
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = torch.arange(12).view(3,4)\n",
    "torch.tensor([0,1,2,3]) in data"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[ True,  True,  True,  True],\n        [False, False, False, False],\n        [False, False, False, False]])"
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data == torch.tensor([0,1,2,3])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0, 1, 2, 3])\n",
      "tensor([4, 5, 6, 7])\n",
      "tensor([ 8,  9, 10, 11])\n"
     ]
    }
   ],
   "source": [
    "for i in data:\n",
    "    print(i)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}